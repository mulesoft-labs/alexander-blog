{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje automatico:\n",
    "\n",
    "Definition: A computer program is said to learn from experience E with respect to some class of task T and performance measure P, if its performance at task in T, as measured by P, improves with experience E.\n",
    "\n",
    "For example, a computer program that learns to play checkers might improve its performance as measured by its ability to win at the class of tasks involving playing checkers games, through experience obtained by playing games against itself. In general, to have a well-defined learning problem, we must identity these three features: the class of tasks, the measure of performance to be improved, and the source of experience:\n",
    "\n",
    "**A checkers learning problem:**\n",
    "\n",
    "* **Task T:** playing checkers\n",
    "* **Performance measure P:** percent of games won against opponents\n",
    "* **Training experience E:** playing practice games against itself\n",
    "\n",
    "**A handwriting recognition learning problem:**\n",
    "\n",
    "* **Task T:** recognizing and classifying handwritten words within images\n",
    "* **Performance measure P:** percent of words correctly classified\n",
    "* **Training experience E:** a database of handwritten words with given classifications\n",
    "\n",
    "One useful perspective on machine learning is that it involves searching a very large space of possible hypotheses to determine one that best fits the observed data and any prior knowledge held by the learner. For example, consider the space of hypotheses that could in principle be output by the above checkers learners. This hypothesis space consists of all evaluation functions that can be represented by some choice of parameters.\n",
    "\n",
    "The hypothesis space is defined by some underlying representation (eg. linear functions, logical descriptions, decision trees, artificial neural networks). These different hypotheses representations are appropriate for learning different kind of target functions. For each of these hypothesis representations, the corresponding learning algorithm takes advantage of a different underlying structure to organize the search through the hypothesis space.\n",
    "\n",
    "Un ejemplo trivial es tener puntos (rojos y azules) en R^2 y tratar de separarlos. Si usamos una recta, es decir algo de la forma f(x) = aX+b, entonces a y b son parámetros de nuestro modelo. Los colores son también parámetros (son nuestras clases). Estamos ajustando un modelo a estos datos. Puede tener diferentes formas el modelo.\n",
    "Ejemplos: una foto tiene una dimensión por cada pixel, y cada foto seria un punto en nuestro espacio de representación.\n",
    "\n",
    "Un programa en machine learning se puede dividir en tres partes: \n",
    "* **Tarea**\n",
    "* **Experiencia**\n",
    "* **Medida de performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paradigmas dentro de aprendizaje automatico:\n",
    "\n",
    "### Aprendizaje supervisado:\n",
    "Le doy como experiencia un conjunto de datos con su correspondiente clasificación para entrenar nuestro algoritmo. Estamos supervisando, ayudando al algoritmo. Dentro de supervisado tenemos dos grandes tipos de algoritmos: Por un lado estan los denominados de clasificacion (dado un mensaje, clasificarlo en SPAM o HAM), y por el otro los de regresion (cada instancia tiene un valor numerico, por ejemplo dado un mail tenemos una probabilidad de que sea SPAM o HAM). La clasificacion aprende una etiqueta mientras que la regresión aprende un numero.\n",
    "\n",
    "Algo importante en este tipo de aprendizaje es elegir atributos. De todos los atributos que decidimos extraer, nos tenemos que quedar con los mejores (para esto se pueden usar tecnicas de reduccion de la dimensionalidad por ejemplo). Luego de extraer atributos y entrenar nuestro algoritmo, tenemos que evaluarlo con un set de datos que no hayamos usado para entrenamiento. Es decir, un set de datos de Test que nos permita verificar efectivamente si nuestro algoritmo generaliza bien o esta super overfiteado a los datos de entrenamiento.\n",
    "\n",
    "### Aprendizaje no supervisado:\n",
    "En este caso tenemos solamente los datos sin ningun tipo de clasificacion. Esto esta muy de moda con big data. Tenemos toneladas de informacion por segundo, y no tenemos ni idea que hacer con eso. Los tratamos de agrupar en conjuntos de semejanza (por ejemplo con clustering). Por ejemplo, bajo una metrica establecida, agrupamos los datos que se encuentran mas cercanos y armamos clusters que reflejan alta semejanza entre sus puntos.\n",
    "\n",
    "### Aprendizaje por refuerzos:\n",
    "Es un aprendizaje gradual. Por ejemplo aprender a jugar al pacman, tengo un conjunto de estados y voy aprendiendo a medida que voy jugando. Paso de un estado a otro. Si estaba en un estado y paso a otro pero me come un fantasmita, aprendo que no tengo que ir por ese lugar. Tengo un conjunto de acciones y estados en este caso. A destacar es que en aprendizaje por refuerzos interactuamos con el medio. Otro ejemplo son los asensores. Por ejemplo un asensor puede ir aprendiendo sobre la marcha como optimizar el tiempo de espera. Cuando el asensor esta sin hacer nada puede decidir si dejar la puerta abierta o cerrada. Puede decidir quedarse en ese piso o moverse a otro, mejorando el tiempo de espera. A lo largo de todo el dia el tiempo que le lleva a una persona desde que aprieta un boton para llamar al asensor hasta que sale de este, esa suma de tiempo sea minima. Por ejemplo, en cierto edificio conviene que el asensor a las 3 de la tarde este parado en el 5to piso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje de conceptos:\n",
    "Tenemos que empezar a aprender conceptos. Por ejemplo aprender a diferenciar aves. Puedo pensar que si tiene plumas y un pico es un ave. Estas son mis hipotesis de que es un ave. Aprender un concepto es inducir una funcion booleana a partir de ejemplos de entrenamiento. Aprender que es un ave es poder decir, esto es o no un ave. Los ejemplos de entrenamiento son, cada vez que veo algo y le pregunto a algun adulto, esto es un ave? Ahi aprendo. Lo que hacemos es construir y evaluar hipotesis. Tiene varios significados una hipotesis: una suposicion que uno hace en algun contexto y un modelo. El modelo de ave. Son las reglas que me permiten clasificar nuevos objetos. Ese modelo me ayuda a predecir nuevas cosas. A ese modelo en ML se le llaman hipotesis. Una hipotesis aca es, que supones vos que es un ave. Cual es tu modelo de ave. Empezamos con vuela, falla, vuela y tiene pico, falla y asi la voy mejorando. Tenemos un espacio de hipotesis, que son todas las hipotesis que existen que me definen ave. Todas las posibles definiciones de ave. Puede ser que todas las posibles formas en que yo puedo modelar el concepto de ave no contengan a la verdadera nocion de ave. Que no tenga los atributos necesarios o que simplemente no sea expresable en este lenguaje. Por ejemplo, con las aves usabamos la logica proposicional. Puedo probar un monton de espacios de hipotesis distintos y que ninguno contenga la definicion exacta de ave (nuestro concepto objetivo). Nos basta conformarnos con una aproximacion a dicho concepto objetivo. Entonces un algoritmo de aprendizaje que hace? Busca en el universo de hipotesis, aquella hipotesis que mejor se ajuste a los datos de entrenamiento. Busco la hipotesis que tenga la mayor probabilidad dado un set de entrenamiento (la que predice mejor sobre ejemplos no vistos por nuestro algoritmo).\n",
    "Encontrar una hipotesis que, dado los datos de entrenamiento, tiene maxima probabilidad. Es la maxima probabilidad a posteriori.\n",
    "\n",
    "Pensemos que ahora volvemos a los puntos en el plano.\n",
    "\n",
    "![title](images/6.png)\n",
    "\n",
    "Quiero aprender ese concepto. Es un concepto que no esta escrito en ningun lado. La unica forma que tengo de llegar a eso es a traves de algunas muestras clasificadas. Tengo una cantidad finita de instancias de entrenamiento. Nuestra H es una funcion que vaya de X a Y. Queremos aproximar la funcion objetivo. Nuestra funcion objetivo es el concepto que queremos aprender.\n",
    "\n",
    "![title](images/7.png)\n",
    "\n",
    "Lo que estamos haciendo aca es aprendizaje inductivo. La induccion no es un proceso logico de por si. Un proceso logico es algo como: \"socrates es hombre, todos los hombres son mortales, ergo socrates es mortal\". Es un razonamiento, una inferencia logica. La induccion es otra cosa. Tenemos una muestra especifica, y a partir de eso construir un modelo general. No tenemos una unica manera de hacerlo. A veces falta muchisima informacion. Como a partir de los datos voy a poder reconstruir el modelo objetivo. Tenemos un salto entre ambas cosas. Supongo que a partir de los datos puedo construir algo que tenga sentido. Tenemos la asuncion de aprendizaje inductivo: cualquier hipotesis que aproxime bien a una funcion objetivo sobre un conjunto sufiicentemente grande de instancias de entrenamiento tambien aproximara bien a la funcion objetivo sobre nuevas instancias. Sobre instancias no observadas. Voy a suponer que eso me va a servir para nuevas instancias. Es la piedra fundamental del aprendizaje automatico. Es un punto de partida. Tengo que confiar en que eso funciona. Estamos diciendo que los datos tienen cierta estructura. El salto inductivo es el hecho de que no me alcanza con lo que observo para generar el modelo objetivo. Si yo pudiera hacer ese salto de lo especifico a lo general de manera directa no existiria el area de ML. Seria puramente logica.\n",
    "\n",
    "Entonces empezamos a probar hipotesis, por ejemplo en el ejemplo de los puntos en el plano, tiramos una recta para separar los datos. Permitimos que nuestros modelos sean los separables por una recta. Buscamos la recta que menos le pifie. Tenemos que ajustar la constante (a, b). El conjunto de hipotesis es el par ordenado.\n",
    "\n",
    "![title](images/8.png)\n",
    "\n",
    "Entonces ajustar ese modelo a estos datos, es buscar el par (a, b) correcto. El espacio de hipotesis son todas las combinaciones posibles de (a, b). Entrenar un modelo que pertenece a este espacio de hipotesis en este caso simplemente es buscar la mejor recta. Eso es ajustar una hipotesis a los datos. Buscar la hipotesis que maximiza la performance para esos datos. A medida que agrego mas parametros, mi espacio de hipotesis es cada vez mas grande. Van a haber muchos conceptos que no pertenezcan al espacio de hipotesis de las rectas. Va a ser menos expresivo nuestro espacio de hipotesis.\n",
    "\n",
    "Los datos de entrenamiento no sirven para deducir formalmente el modelo.\n",
    "\n",
    "Tenemos nuestro algoritmo y un conjunto de instancias. Todo conjunto de instancias posibles. C es el concepto a aprender. D es el conjunto de instancias de aprendizaje (instancias con sus clases). Y por ultimo tenemos la clasificacion que L va a asignar a una instancia nueva dado los datos de entrenamiento.\n",
    "\n",
    "![title](images/9.png)\n",
    "\n",
    "Dado una nueva instancia, no puedo inferir logicamente cual es la clasificacion dados los datos de entrenamiento. L es un algoritmo entrenado con los datos de entrenamiento. No hay una forma algoritmica de llegar de un lado al otro. Necesitamos algo mas.\n",
    "\n",
    "![title](images/10.png)\n",
    "\n",
    "Ahora si puedo razonar, inferir la clasificacion correcta de la nueva muestra. B es el conjunto minimal de afirmaciones necesarias para que esto sea asi (un proceso algoritmico). Es el sesgo inductivo. El sesgo inductivo de un algoritmo L cualquiera es un conjunto de afirmaciones necesarias para poder clasificar instancias del modelo de manera deterministica. Cada algoritmo que vamos a ver va a tener un conjunto de afirmaciones, va a decir por ejemplo, las hipotesis tienen esta forma y voy a usar estos atributos, y dados todas estas afirmaciones esto va a ser una inferencia. Si lo que vamos a hacer es construir arboles de decision, con determinado algoritmo, con determinada forma de ir agregando nodos al arbol, determinada forma de elegir los atributos, bueno, esa forma, esos algoritmos de construir las hipotesis son el conjunto de afirmaciones que hacen que yo le de datos, entreno el algoritmo y me pueda clasificar instancias no observadas (de manera deterministica). Por ejemplo, en el modelo que separabamos con rectas, un conjunto de afirmaciones podria ser que todas las rectas son rectas verticales. Lo unico que puedo hacer es poner rectas verticales. Lo que hace el algoritmo es decirme donde colocar la recta vertical de manera que me separe mejor las clases. Donde minimizas el error de los datos de entremaiento. Otro sesgo inductivo puede ser que son rectas, otro que son parabolas. Una vez que uno define que las hipotesis tienen forma de recta o parabolas, ya esta definiendo deterministicamente el procedimiento de inferencia. La induccion esta determinada cuando uno fija el sesgo inductivo.\n",
    "\n",
    "Otro tipo de modelos puede ser, pongo cajas. Ajusto el alto, ancho y posicion de la caja. El algoritmo me busca la mejor hipotesis. Si un cuadrado esta bueno, entonces metamos mas de uno. Pongamos muchos. Si tenemos varios rectangulos podemos atrapar mejor las clases. Tengo una nueva explosion en mi espacio de hipotesis que es tomar la decision de cuantos rectangulos usar.\n",
    "\n",
    "![title](images/11.png)\n",
    "\n",
    "En el peor caso, cada punto de una clase esta encerrado en una cajita. Esto no generaliza nada. Esta mega overfiteado.\n",
    "\n",
    "![title](images/12.png)\n",
    "\n",
    "La intuicion que tenemos de que eso no generaliza se denomina la navaja de occam. Hay que buscar la explicacion mas simple. No hay que ir a cosas complejas si no es necesario. Hay que apuntar a hipotesis simples, especificaciones simples. Para que subir la cantidad de rectangulos. Ambas son igual de buenas clasificando los datos de entrenamiento pero la primera es muchisimo mas simple. Estamos acostumbrados a hacer esto en la vida real. Es un principio, una suposicion. Hay casos en los cuales esto falla. No siempre el modelo mas simple es el mejor, pero es una buena heuristica. Por ejemplo cuando tenemos varias hipotesis equivalentes, el algoritmo desempata agarrando la mas simple.\n",
    "\n",
    "Clave: encontrar la mejor hipotesis que maximice cierta funcion objetivo.\n",
    "\n",
    "$H_{MAP}$: hipotesis maxima a posteriori.\n",
    "\n",
    "Entonces, **que es machine learning?** Es dado los datos de entrenamiento, buscar en mi espacio de hipotesis aquella que maximiza la probabilidad. Esa hipotesis es la hipotesis maximza a posteriori.\n",
    "\n",
    "**Probabilildad a priori:**\n",
    "Es una probabilidad que no depende de los datos. Aca podemos entre otras cosas meter el hecho de que queremos soluciones mas simples, dandole probabilidades muy bajas a aquellas hipotesis que sean complicadas. Pocos rectangulos va a ser mas probable a priori que muchos rectangulos. La verosimilitud es, supongamos la hipotesis que estoy viendo ahora es cierta, cual es la probabilidad de que los datos hayan salido de ese mundo en el cual la hipotesis es cierta. Cuan compatible son los datos de entrenamiento suponiendo que esta hipotesis es cierta. Si ponia en el ejemplo de la recta, la recta vertical muy a la izquierda, los datos eran muy inverosimiles dado ese concepto, dada esa hipotesis. Cuando todas las hipotesis son equiprobables, hablamos de encontrar la hipotesis de maxima verosimilitud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y validacion:\n",
    "\n",
    "PONER GRAFIQUITO DE ENTRENAMIENTO Y VALIDACION\n",
    "\n",
    "Vamos a entrenar un algoritmo (algun tipo de modelo de clasificacion) con las instancias de entrenamiento que separamos. Construimos un modelo que funcione bien para los datos de entrenamiento. Y lo vamos a validar sobre el conjunto de instancias restantes. Esto se llama validacion cruzada.\n",
    "\n",
    "Notar que algo muy importante es hacer esta separacion de datos de test y datos de entrenamiento de manera azarosa. Pero que puede pasar si tenemos mucha mala suerte al separarlos?\n",
    "\n",
    "**k-Fold Cross Validation**\n",
    "\n",
    "Desordenar los datos\n",
    "Separar en k folds del mismo tamaño\n",
    "Para i = 1..k\n",
    "Entrenar sobre todos los folds menos en el i\n",
    "Evaluar sobre el fold i\n",
    "\n",
    "## PONER GRAFIQUITO DE K-FOLD VALIDATION\n",
    "\n",
    "Con esto safo del problema de tener suerte o no al separar datos de entrenamientos. Si k = 5 entrene 5 veces al modelo con 5 separaciones distintas. Tengo 5 medidas de accuracy distintas. Con esas 5 medidas podemos calcular el promedio y su varianza a ver que tal anda.\n",
    "\n",
    "Podes sacar conclusiones de por ejemplo, la profundidad sea 6 y postpruning sea tal otra cosa.\n",
    "Bueno, entonces queremos comparar dos hipotesis (2 modelos) $h_{1}$ y $h_{2}$. Tenemos dos opciones:\n",
    "\n",
    "* Comparar solo la exactitud media de c/u\n",
    "Contra: no podemos saber si diferencias pequeñas son en realidad una consecuencia del azar.\n",
    "\n",
    "* Comparar los ectores de resultados de los k folds con un test estadistico.\n",
    "\n",
    "K fold CV para h1 -> <...>\n",
    "\n",
    "k fold CV para h2 -> <...>\n",
    "\n",
    "Test apareado entre ambos vectores por ejemplo output del test con p-valor.\n",
    "\n",
    "Con esto voy sacando conclusiones sobre mis hiperparametros y voy ajustando a mis datos. Puede ser que esto tambien me de informacion de que me estan faltando atributos. Voy y meto mas atributos y vuelvo a hacer k-Fold. Voy manoseando los datos muchisimo y al final de todo este proceso me sobre ajuste a otro nivel a los datos. La metodologia me hace sobreajustar.\n",
    "\n",
    "**Escenario frecuente:**\n",
    "* Conseguimos un dataset.\n",
    "* Experimentamos mucho: extraemos y elegimos atributos, probamos algoritmos, ajustamos parámetros.\n",
    "* Llegamos a un modelo que funciona “bien”.\n",
    "* Lo ponemos a funcionar con datos nuevos, y los resultados son bastante peores.\n",
    "* ¿Qué falló?\n",
    "\n",
    "**Otro nivel de sobreajuste.**\n",
    "* Sobreajustamos nuestra experimentación a los datos.\n",
    "\n",
    "**¿Solución?**\n",
    "* Lo antes posible, hay que separar un conjunto de datos de test (test set), y NO TOCARLOS hasta el final.\n",
    "* Todas las pruebas y ajustes se hacen sobre el conjunto de datos de desarrollo (dev set).\n",
    "* Cuando termina el desarrollo, se evalúa sobre los datos de test separados. La estimación de performance será más realista.\n",
    "* ¡No volver atrás!\n",
    "\n",
    "PONER FOTITO DE DESARROLLO Y TEST\n",
    "\n",
    "# Metricas\n",
    "\n",
    "## Evaluacion de hipotesis:\n",
    "Como hacemos para saber que tan buena es una hipotesis? Podemos comparar nuestra hipotesis con el concepto? No porque no tenemos una comparacion directa. No podemos saber directamente si aprendimos bien o mal. La idea es ver cuan buena es una hipotesis.\n",
    "\n",
    "## Medidas de performance:\n",
    "**Un modelo tiene una exactitud (accuracy) del 95%.**\n",
    "* O sea, de cada 100 instancias, clasifica bien 95.\n",
    "\n",
    "**¿Qué significa esto?**\n",
    "* Según la tarea y la distribución de clases en el dominio, 95% puede ser muy bueno o pésimo.\n",
    "* No dice nada sobre el tipo de aciertos y errores que comete el modelo.\n",
    "\n",
    "**Ejemplos:**\n",
    "\n",
    "* **Filtro de spam**:\n",
    "Descarta directamente los mails sospechosos. Imaginense que el filtro agarra los mail que clasifico como spam y los elimina. Pensemos cuando le pifiamos. Un mail genuino podemos marcarlo como spam y tirarlo y a un mail como spam podemos considerarlo que no es spam. Cual de los dos errores es mas terrible? Claramente el primero. Es un error mucho mas grave. El balance de errores es bastante disparejo. El accuracy no me dice nada de que tipo de error estoy generando.\n",
    "\n",
    "* **Detección de fraude**:\n",
    "Prepara un listado de casos sospechosos para ser revisados por humanos. Aca que conviene? Dejar pasar un acto fraudulento  o manejar como sospechoso un caso en el que no paso nada? Mejor dejar pasar y que lo vea un ser humano. A la inversa que con el spam.\n",
    "\n",
    "* **Identificación de meteoritos**:\n",
    "Agarro una piedra por el camino y me pregunto si es un meteorito. El algoritmo dice (Start -> no es un meteorito). Esto si usamos un set de entrenamiento de las piedras en la tierra va a tener un accuracy del 99.999%. Sirve para algo esta metrica en este caso? No.\n",
    "\n",
    "Hay que encontrar una manera de ponderar los tipos de errores.\n",
    "\n",
    "PEGAR DIBUJITO DE MATRIZ DE CONFUSION Y TODAS LAS FORMULAS\n",
    "\n",
    "## Accuracy:\n",
    "Porcentaje de datos de entrenamiento clasificados correctamente.\n",
    "\n",
    "## Precision:\n",
    "De todos los que dijimos “si son positivos”, cuantas veces eso estuvo bien. Que porcentaje de veces dijimos bien.\n",
    "\n",
    "## Recall: \n",
    "De todos los casos de spam reales vamos a ver cuantos efectivamente los mostramos como spam.\n",
    "\n",
    "## F-measure:\n",
    "Combina ambas metricas. Tambien conocida como $F_{1}$ Measure. Se generaliza a la $F_{\\beta}$. Podemos jugar con ese $\\beta$ para enfatizar recall ($\\beta$ = 2) o precision ($\\beta$ = 0.5). Si gano de uno, pierdo del otro.\n",
    "\n",
    "PONER DIBUJITO DE CURVAS PRECISION * RECALL\n",
    "\n",
    "**Documento recuperado** = positivo predicho (ej: mail clasificado como spam por el modelo)\n",
    "**Documento relevante** = positivo real (ej: mail anotado como spam por el usuario.)\n",
    "\n",
    "**Precision** son de los documentos recuperados, que porcentaje son relevantes.\n",
    "**Recall** son de los documentos relevantes, que porcentaje fueron recuperados.\n",
    "\n",
    "**Filtro de spam:** si priorizamos recall estariamos diciendo que de todos los spam que estan ahi quiero descartar la maxima cantidad. Puedo maximizar el recall tirando absolutamente todo. Todo digo que es spam y lo elimino. Tengo que maximizar la precision.\n",
    "Deteccion de fraude: quiero priorizar el recall. Quiero descartar la mayor cantidad de actividades fraudulentas, pero si una fraudulenta pifie y dije que no era, luego la revisa un humano y se da cuenta que es fraudulenta.\n",
    "\n",
    "## Curva ROC:\n",
    "\n",
    "![title](images/13.png)\n",
    "\n",
    "**TPR:** de todos los positivos, a que proporcion pudimos marcar.\n",
    "**FPR:** de todos los negativos, a cuantos le pifiamos\n",
    "\n",
    "El clasificador perfecto tiene TPR = 1 osea le pega siempre y no tiene ningun falso negativo, no se le escapa ninguno.\n",
    "Como construir la curva? Vamos a variar el umbral de deteccion entre 0 y 100%. Para cada valor corro mi algoritmo de clasificacion que me devuelve no una clase sino un porcentaje de pertenencia a la clase positiva, entonces para cada una de estas voy a decidir bajo un umbral decidir si le doy bola o no a decir que es positiva la instancia y pongo un puntito. Cada curva se puede condensar en un numero, el area bajo la curva. Esto nos permite comparar varios clasificadores. Si necesitamos tener un numero para decidir que algoritmo elegir, esto es muy util."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos\n",
    "Queremos aproximar un concepto, una función objetivo de manera automatica. Ejemplo de funcion de objetivo de tenis:\n",
    "\n",
    "Tenis: Cielo x Temperatura x Humedad x Viento -> {Si, No}\n",
    "\n",
    "Tenemos un conjunto de hipotesis. Este conjunto de hipotesis son funciones parecidas a la F (nuestra funcion objetivo). Depende del algoritmo de aprendizaje.\n",
    "\n",
    "Que es el algoritmo de aprendizaje? Una entrada posible es un conjunto de instancias y sus clasificaciones. La salida del algoritmo es una h que mejor aproxime.\n",
    "\n",
    "## Arboles de decision:\n",
    "Lo que tenemos es una F que va de los atributos a la clase, cada nodo interno evalua un atributo discreto, cada rama corresponde para un valor de ese atributo y cada hoja es una clase.\n",
    "\n",
    "**Induccion Top-Down de Arboles de decision:**\n",
    "\n",
    "1. A ← el “mejor” atributo para nodo_actual.\n",
    "2. Asignar A como atributo de decisión del nodo_actual.\n",
    "3. Para cada valor de A, crear un nuevo hijo del nodo_actual.\n",
    "4. Clasificar (repartir) las instancias en los nuevos nodos (según el valor de A).\n",
    "5. Si las instancias están clasificadas perfectamente: FIN. Si no: iterar sobre los nuevos nodos.\n",
    "\n",
    "La entropia mide cuan sucia, dispersa, heterogenea esta la informacion. Agarramos algunas instancias de alguna poblacion (una muestra) y vamos a ver la entropia de esa muestra con respecto de una variable objetivo Y.\n",
    "\n",
    "Si son todos de river, tenemos entropia 0, al igual que si tenemos ninguno de river. La entropía es máxima cuando tenemos la muestra totalmente bien desprolija. La mitad de cada uno, representantes de todas las clases por igual.\n",
    "\n",
    "La idea es reducir la entropia lo mas que podamos. Elijo un atributo y parto la muestra en sub muestras. Ahi veo si la entropía de la cual partia es menor a la suma ponderada de las entropias resultantes. Buscamos el atributo que mas nos disminuya la entropia. Entonces en cada nodo elegimos el atributo con mayor ganancia de informacion (el mas informativo).\n",
    "\n",
    "**Espacio de hipotesis:**\n",
    "Espacio completo de funciones de valores discretos. En principio puede construirse cualquier arbol. Puede modelar el espacio de funciones de valores discretos.\n",
    "\n",
    "**Sesgo inductivo (como funciona el algoritmo):**\n",
    "Partiendo de arboles simples, los vamos complejizando agregandole nuevos niveles de profundidad (construccion de arboles cada vez mas complejos).\n",
    "\n",
    "**Metodo:**\n",
    "Hill-climbing sin backtracking (converge a max. local).\n",
    "\n",
    "**Atributos mas informativos -> cerca de la raiz (no tiene porque ser bueno esto)**\n",
    "\n",
    "**Atributos Numéricos**\n",
    "\n",
    "* ¿Qué pasa si tenemos un atributo numérico A?\n",
    "Buscamos un umbral c, para discriminar según A<c.\n",
    "\n",
    "* ¿Cómo elegir c?\n",
    "1. Ordenar las instancias según A.\n",
    "2. Buscar la forma de partir la lista que maximice la ganancia de información.\n",
    "\n",
    "* ¿Cuán robustos son los Árboles de Decisión ante atributos faltantes?\n",
    "Una solucion podria ser rellenar esos campos que faltan con la media.\n",
    "\n",
    "* Y si tenemos instancias de entrenamiento con valores indefinidos en algunos atributos, Ej.: datos clínicos de un paciente incompletos o poseemos datos ruidosos?\n",
    "El algoritmo lo que hace es estadistica, agarra muestras y dice, la mayoria pasa esto. Podemos usar la media, mediana, etc, que poseen robustez ante outliers. Es un algoritmo basado en estadística sobre muestras por lo que es relativamente robusto ante datos ruidosos.\n",
    "\n",
    "* Y si ahora tenemos instancias de entrenamiento mal clasificadas, como por ejemplo errores cometidos en las anotaciones manuales?\n",
    "Llegamos a un atributo y vemos que no esta clasificado. Que hacemos? Puedo elegir el mas probable de las dos ramas.\n",
    "\n",
    "A medida que el arbol es mas profundo, voy mejorando la descripcion de los datos de entrenamiento. Cuando empiezo con el arbol vacio, no describo nada. Si es muy profundo seria como un if gigante. Medir exactitud sobre datos de entrenamiento es una mala idea.\n",
    "\n",
    "Una definicion un poco mas formal de **sobre-ajuste** seria:\n",
    "\n",
    "Dado el error sobre un conjunto de entrenamiento y el conjunto de todas las instancias posibles, h se sobreajusta a los datos de entrenamiento si existe h’ tal que:\n",
    "\n",
    "error_entrenamiento(h) < error_entrenamiento(h’) y error_todo(h) > error_todo(h’)\n",
    "\n",
    "Es decir H efectivamente funciona mejor sobre los datos de entrenamiento pero no para todas las instancias posibles. H prometia un monton pero en la vida real falla. Se ajusto demasiado. Lo que quiere decir es que probablemente siempre caigas en algo de sobreajuste pero hay que tratar de modelarlo. Un threshold de cuanto sobreajuste me banco.\n",
    "\n",
    "PONER GRAFICO DE SOBREAJUSTE DE ARBOLES\n",
    "\n",
    "## Soluciones:\n",
    "\n",
    "* **Criterio de parada**\n",
    "No construir más allá de cierta profundidad.\n",
    "\n",
    "* **Pruning (poda)**\n",
    "Construir el árbol entero; podar las ramas cuando ello mejore la exactitud sobre datos separados. Voy rama por rama viendo si cortando por ahi y testeo sobre datos separados, mejora o no la performance (accuracy en este caso). Osea al set de entrenamiento lo parto en un set de testeo (ojo que entreno con todo el set de datos). Cual es el umbral para cortar o no cortar es parte del sesgo inductivo.\n",
    "\n",
    "* **Rule post-pruning**\n",
    "Construir el árbol entero; convertir árbol a reglas; sacar precondiciones de las reglas cuando ello mejore su exactitud sobre datos separados; reordenar las reglas segun exactitud. Crea un arbol entero, lo convierte a reglas (como son las reglas? Si decia si cielo es igual a sol y humedad es igual a alta entonces no juegues). Sacamos condiciones de las reglas. Las reglas son todas conjunciones de precondiciones. Vamos a ir volando de a una precondicion a la vez y ver si mejora sobre los datos separados. Como ir sacando precondiciones, de izquierda a derecha o al revez, todo eso es parte del sesgo inductivo.\n",
    "\n",
    "## Naive Bayes:\n",
    "Espacio de hipótesis:\n",
    "Sesgo inductivo: \n",
    "\n",
    "## KNN:\n",
    "### Espacio de hipótesis:\n",
    "Los espacios de voronoi. Y algo sumamente fuerte es que puntos que estan cerca deberian ir a la misma clase.\n",
    "\n",
    "### Sesgo inductivo:\n",
    "\n",
    "### Distance-Weighted KNN:\n",
    "\n",
    "Que pasa con la distancia? Se calcula sobre todos los atributos, y si algunos son irrelevantes? Si tenemos mucho ruido hay que ver como definir la distancia.\n",
    "\n",
    "## SVM:\n",
    "Busca un hiperplano de margen maximo que separe nuestras clases.\n",
    "\n",
    "![title](images/14.png)\n",
    "\n",
    "Ahora, que sucede si nuestras clases no son linealmente separables?\n",
    "\n",
    "### Kernel Trick:\n",
    "\n",
    "![title](images/15.png)\n",
    "![title](images/1.png)\n",
    "\n",
    "### Espacio de hipótesis:\n",
    "Fijamos un kernel de grado 3. Todos los posibles hiperplanos en ese espacio superior que me permiten separar las clases. La forma de elegir una hipotesis es maximizando el margen.\n",
    "\n",
    "### Sesgo inductivo:\n",
    "Fijar un kernel y maximizar el margen de separacion de un hiperplano entre las clases.\n",
    "\n",
    "### Sesgo y varianza:\n",
    "\n",
    "## Conjunto de clasificadores:\n",
    "\n",
    "**Entrenar un modelo, permitir el sobreajuste:**\n",
    "* Por ejemplo: árboles muy profundos.\n",
    "* Bajo sesgo; alta varianza.\n",
    "\n",
    "**Entrenar varios modelos, c/u sobre datos distintos.**\n",
    "* Cada modelo sobreajusta de manera diferente.\n",
    "\n",
    "**Cada modelo: bajo sesgo, alta varianza.**\n",
    "* Votación: Para una nueva instancia, devolver la clase más elegida.\n",
    "\n",
    "**Esta votación reduce la varianza de la clasificación. ¡Magia!**\n",
    "\n",
    "**Si los modelos individuales devuelven probabilidades, se puede hacer una votación ponderada.**\n",
    "\n",
    "**En regresión, se puede devolver el promedio de los valores devueltos por los modelos individuales.**\n",
    "\n",
    "**Problema de bagging con árboles:**\n",
    "* Si pocos atributos son predictores fuertes, todos los árboles se van a parecer entre sí. \n",
    "* Esos atributos terminarán cerca de la raíz, para todos los conjuntos generados con bootstrap. \n",
    "\n",
    "## Random Forest:\n",
    "* Igual a bagging, pero en cada nodo, considerar sólo un subconjunto de atributos elegidos al azar.\n",
    "\n",
    "### Boosting\n",
    "* Comenzar con un modelo (simple) entrenado sobre todos los datos: $h_{0}$\n",
    "* En cada iteración i, entrenar $h_{i}$ dando (gradualmente) mayor importancia a los datos mal clasificados por las iteraciones anteriores.\n",
    "* Terminar al conseguir cierto cubrimiento, o luego de un número de iteraciones.\n",
    "* Clasificar nuevas instancias usando una votación ponderada (p.ej.) de todos los clasificadores construidos.\n",
    "\n",
    "### Stacking\n",
    "* Entrenar diferentes modelos (modelos base) y un modelo más, que decide, dada una instancia nueva, qué modelo usar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series temporales\n",
    "\n",
    "\n",
    "## Introduccion\n",
    "\n",
    "Una serie temporal es una serie de puntos indexados ordenados en el tiempo. Se considera que entre una muestra y la otra siempre hay el mismo espacio.\n",
    "\n",
    "**Random variation**\n",
    "\n",
    "Toda colección de datos tomada en el tiempo tiene ruido. Es un error de medición aleatorio, puede ser que el sensor dependiendo de la temperatura cambie su comportamiento, etc. Cuando nos llegan estos datos, llegan sucios.\n",
    "\n",
    "Hay técnicas para suavizar estas curvas que tienen ruido. Compensar el ruido que tuve en un momento dado con el ruido que tuve un poquito antes suponiendo que como es aleatorio se compensa uno con el otro.\n",
    "\n",
    "Métodos de reducción de ruido: **“smoothing” (alisamiento)**\n",
    "* **Alisamiento por medias**\n",
    "* **Alisamiento exponencial**\n",
    "\n",
    "El tema que si hacemos por media, puede ser que nuestra curva tenga una pendiente. Entonces calcular la media sobre todos los datos no sirve, hagamosla solo en un entornito chiquito, agarremos 3 anteriores y calculamos la media. Entonces de esta manera puedo alisar tendencias. Esto es el famoso **moving average**. Cuantos puntos agarro? Existen tantos moving average como decisiones tomemos. Cada uno tiene su teoría de cual es el mejor y algunos son muy muy estándar. Lo que se suele usar es que el peso de los puntos anteriores que uno toma decrece exponencialmente (**Exponentially Weighted Moving Average**)\n",
    "\n",
    "Ahora bien, cómo hacemos para comparar si nuestra estimación es buena? Lo que podemos hacer es calcular el error, es decir, la resta entre la estimación y el valor real. En la práctica lo que se hace es el error al cuadrado.\n",
    "Ahora bien, podemos hacer la suma de todos estos errores al cuadrado y tener en un numerito, que tan bueno es nuestro modelo. Es cierto esto? Realmente no, veamos el principal inconveniente de usar esta métrica.\n",
    "\n",
    "Notemos que los errores al cuadrado siempre son positivos, entonces la suma es estrictamente positiva. Si nosotros tenemos una serie aproximada por un modelo lineal con 20 puntos y otra con 40 puntos, que me indica el SSE (suma de errores al cuadrado) en cada una? Notar que a mas puntos, voy a estar sumando más términos en mi SSE.\n",
    "\n",
    "Tenemos que pensar otra cosa. Podemos calcular por ejemplo la media. Cual es el promedio de los errores cuadráticos (MSE).\n",
    "\n",
    "Vamos primero con una definición. Serie estacionaria:\n",
    "\n",
    "Se dice que una serie de tiempo es estacionaria cuando su distribución y sus parámetros no varían con el tiempo. En términos más concretos, la media y la varianza de una serie estacionaria no cambian con el tiempo, y tampoco siguen una tendencia.\n",
    "\n",
    "Si lo ilustramos con las siguientes imágenes, lo podrás ver de una forma mucho más clara:\n",
    "\n",
    "## FALTA UNA IMAGEN ACA!! VER DIAPOS DE DATOS TAMBIEN!!\n",
    "\n",
    "Algo que me gustaría decidir es si una serie es estacionaria o no. Un test de hipótesis para evaluar esto puede ser el **Test de Dickley-Fuller**. Supone que hay una tendencia (es decir, que no es estacionaria), y quiere rechazar esto. Es muy poco probable que esa serie venga de una distribución de probabilidad que tenga tendencia (si el p-valor es muy chico).\n",
    "\n",
    "**Goodness of fit**: cuan bueno es el fiteo de mi modelo. Un primer approach es medir el promedio de los errores cuadráticos.\n",
    "\n",
    "Es bueno elegir el modelo que menor MSE me de en los datos nuevos? A primera vista si. Pero qué pasa si le ponemos muchos parámetros? Es decir, que nuestra regresión lineal tenga varios beta a estimar? Por ejemplo, usar un polinomio de grado alto. Vamos a tener error 0 basicamente, y quizá (seguramente) esto no generaliza nada! Por eso es de suma importancia separar un set para entrenar nuestro regresor, y otra para testear.\n",
    "\n",
    "Notar que tenemos un intervalo de confianza entorno a los Beta que nos dice en qué entorno tenemos 95% de probabilidad de encontrar a esos Beta. Esto es debido a que tenemos un error en nuestras mediciones, y los Beta que calculemos para una muestra luego en otra muestra pueden ser distintos! Si nuestro intervalo es pequeño, entonces van a ser parecidos. Sería muy distinto el Beta si replico muchas veces este experimento con distintas mediciones? Esto nos dice el intervalo de confianza. Notar que definimos que el error de medicion es normal para poder calcular los intervalos de confianza.\n",
    "\n",
    "## Tendencias lineales:\n",
    "\n",
    "### Regresión Lineal Simple\n",
    "Consiste en predecir una respuesta cuantitativa Y en base a una única variable predictora X.\n",
    "\n",
    "![title](images/series/1.png)\n",
    "\n",
    "Vamos a estimar $B_{0}$ y $B_{1}$. Una vez hecho esto nos queda la siguiente formula:\n",
    "\n",
    "![title](images/series/2.png)\n",
    "\n",
    "Para encontrar dichas estimaciones vamos a definir lo que es el residuo o error de prediccion:\n",
    "\n",
    "![title](images/series/3.png)\n",
    "![title](images/series/4.png)\n",
    "\n",
    "Ahora definimos el RSS (Residual sum of squares):\n",
    "\n",
    "![title](images/series/5.png)\n",
    "\n",
    "Los residuos se elevan al cuadrado para sacar el signo y para que RSS sea diferenciable\n",
    "Para estimar los coeficientes, buscamos minimizar RSS. Para esto derivamos RSS respecto de $B_{0}$ y $B_{1}$. Notar que no es robusto ante outliers, ya que RSS penaliza los residuos grandes. Es decir, si nos movemos entre valores cercanos al 0 y de golpe un error de medicion nos brinda una instancia con valor 1 millon, esto nos va a penalizar fuertemente.\n",
    "\n",
    "![title](images/series/6.png)\n",
    "\n",
    "El intercept es el $B_{0}$ y el $B_{1}$ es la pendiente o el coeficiente asociado a la variable superficie. Estamos tratando de evaluar la bondad de dos coeficientes. Para eso se usa el **Standard Error** que me da un valor, ese valor en terminos absolutos no me va a decir demasiado, hay que mirarlos con algo mas. Me da el intervalo de confianza (Es util para estimar intervalos de confianza de las predicciones). El standard error es el punto de partida que me lleva a la columna del p-value. Que es esto? Hacemos experimentos y necesitamos una nocion de cuan bueno es el resultado obtenido. Calculamos primero un **T-Test (test de student)**, es un test estadistico que me permite saber cual es la probabilidad que esa estimacion sea distinta de un numero. El p-valor es el resultado del T-Test. Si es bajo (por ejemplo menor a 0.01) tenemos buenas chances de que el $B_{i}$ correspondiente sea significativo. Es improbable que el valor que nos da de $B_{i}$ sea consecuencia del azar. Es decir, observamos los datos, ajustamos un modelo, tenemos los predictores para $B_{i}$, calculo el standard error, calculo el T-Test y veo que me da como p-valor. Si el p-valor de $B_{i}$ me da bajo quiere decir que tengo buenas chances de que no sea consecuencia del azar, es decir que tuve suerte y que los datos me vinieron de tal manera que si agarro un nuevo set de datos me da otra cosa totalmente diferente. Si yo replico esto con una nueva muestra dentro de la misma poblacion es muy probable que caiga en un valor parecido. El p-valor esta asociado a una nocion de cuan significativos son los resultados y esa nocion es variable cuando definimos que seria un p-valor bajo. Si te da un p-valor alto quiere decir que no le des bola al $B_{i}$. Por como son los datos, tenes evidencia que si corres de nuevo el experimento, te va a dar otra cosa. Es demasiado amplio el intervalo de confianza que surge. El p-valor nos dice cuán seguro que ese Beta que te devolví sea realmente un número distinto de 0. El T-test es parametrico, tomamos como condicion que el termino del error es una normal (0, algo) con lo que los residuos estan distribuidos normalmente.\n",
    "\n",
    "Ahora pasamos a que me diga el accuracy, o el F-measure. Para eso se usa la metrica $R^{2}$. Por un lado tenemos la RSS que es la sumatoria de los residuos al cuadrado. Esto me da una nocion de cuanto le pifio el modelo, es lo que queremos minimizar para que el modelo sea lo mas justo, exacto posible. Es una metrica que no es muy util. Es un valor absoluto que depende de los datos que observamos. Queremos algo mas manejable, algo entre 0 y 1 seria buenisimo. Si te da 1 es 100% por ejemplo. Eso es lo que captura $R^{2}$. **Es la variabilidad no explicada por el modelo**. Todo lo que se le escapa al modelo. Si vale 0 es cuando el modelo explica poco de la variabilidad de los datos. Si vale 1 es cuando el modelo explica mucho de la variabilidad de los datos.\n",
    "\n",
    "Ahora definimos el TSS que es muy parecido. Es la distancia de cada uno de las instancias a lo largo de la dimension i a la media al cuadrado. Es la variabilidad total de los datos. Para todos los datos, es como que pongo aca la media y tome eso como mi modelo base contra el cual comparar. Veo como se comporta la regresion lineal que acabo de ajustar comparado con ese modelo. Es como una varianza sin dividir por el N, sin normalizar. Definimos $R^{2}$. Es cuanto mejore al usar un modelo de regresion lineal. Aca use un modelo bien tonto, aca un modelo mejor al tonto y la diferencia va a ser cuanto mejore. Eso lo normalizo y me da un numero entre 0 y 1. Ojo que puede dar menor que 0! No puede dar mayor que uno. Es 0 cuando el error que genera la recta horizontal es igual al error que genera nuestro modelo. Puede dar negativo tanto como yo quiera. Esta metrica la podemos usar para hacer cross-validation, para entrenar, para elegir atributos, etc.\n",
    "\n",
    "![title](images/series/7.png)\n",
    "\n",
    "### Regresión Lineal Simple\n",
    "Consiste en predecir una respuesta cuantitativa Y en base a una única variable predictora X.\n",
    "Vamos a estimar $B_{0}$ y $B_{1}$. Una vez hecho esto nos queda la siguiente formula:\n",
    "\n",
    "## ACA FALTA ALGO!!\n",
    "\n",
    "Para encontrar dichas estimaciones vamos a definir lo que es el residuo o error de prediccion:\n",
    "\n",
    "## CREO QUE TODO ESTO ESTA REPETIDO\n",
    "\n",
    "**RSS (Residual sum of squares):**\n",
    "\n",
    "Los residuos se elevan al cuadrado para sacar el signo y para que RSS sea diferenciable. Para estimar los coeficientes, buscamos minimizar RSS. Para esto derivamos RSS respecto de $B_{0}$ y $B_{1}$. Notar que no es robusto ante outliers, ya que RSS penaliza los residuos grandes.\n",
    "\n",
    "El intercept es el $B_{0}$ y $B_{1}$ es la pendiente o el coeficiente asociado a la variable superficie. Estamos tratando de evaluar la bondad de dos coeficientes. Para eso se usa el Standard Error que me da un valor, ese valor en terminos absolutos no me va a decir demasiado, hay que mirarlos con algo mas. Me da el intervalo de confianza (Es util para estimar intervalos de confianza de las predicciones). El standard error es el punto de partida que me lleva a la columna del p-value. Que es esto? Hacemos experimentos y necesitamos una nocion de cuan bueno es el resultado obtenido. Calculamos primero un T-Test (test de student), es un test estadistico que me permite saber cual es la probabilidad que esa estimacion sea distinta de un numero. El p-valor es el resultado del T-Test. Si es bajo (por ejemplo menor a 0.01) tenemos buenas chances de que el B_i correspondiente sea significativo. Es improbable que el valor que nos da de B_i sea consecuencia del azar. Es decir, observamos los datos, ajustamos un modelo, tenemos los predictores para B_i, calculo el standar error, calculo el T-Test y veo que me da como p-valor. Si el p-valor de B_1 me da bajo quiere decir que tengo buenas chances de que no sea consecuencia del azar, es decir que tuve suerte y que los datos me vinieron de tal manera que si agarro un nuevo set de datos me da otra cosa totalmente diferente. Si yo replico esto con una nueva muestra dentro de la misma poblacion es muy probable que caiga en un valor parecido. El p-valor esta asociado a una nocion de cuan significativos son los resultados y esa nocion es variable cuando definimos que seria un p-valor bajo. Si te da un p-valor alto quiere decir que no le des bola al B_i. Por como son los datos, tenes evidencia que si corres de nuevo el experimento, te va a dar otra cosa. Es demasiado amplio el intervalo de confianza que surge. El T-test es parametrico, tomamos como condicion que el termino del error es una normal (0, algo) con lo que los residuos estan distribuidos normalmente.\n",
    "\n",
    "Ahora pasamos a que me diga el accuracy, o el F-measure. Para eso se usa la metrica R^2 (r cuadrado). Por un lado tenemos la RSS que es la sumatoria de los residuos al cuadrado. Esto me da una nocion de cuanto le pifio el modelo, es lo que queremos minimizar para que el modelo sea lo mas justo, exacto posible. Es una metrica que no es muy util. Es un valor absoluto que depende de los datos que observamos. Queremos algo mas manejable, algo entre 0 y 1 seria buenisimo. Si te da 1 es 100% por ejemplo. Eso es el R cuadrado. Es la variabilidad no explicada por el modelo. Todo lo que se le escapa al modelo. Si vale 0 es cuando el modelo explica poco de la variabilidad de los datos. Si vale 1 es cuando el modelo explica mucho de la variabilidad de los datos. Ahora definimos el TSS que es muy parecido. Es la distancia de cada uno de las instancias a lo largo de la dimension i a la media al cuadrado. Es la variabilidad total de los datos. Para todos los datos, es como que pongo aca la media y tome eso como mi modelo base contra el cual comparar. Veo como se comporta la regresion lineal que acabo de ajustar comparado con ese modelo. Es como una varianza sin dividir por el N, sin normalizar. Definimos R cuadrado. Es cuanto mejore al usar un modelo de regresion lineal. Aca use un modelo bien estupido, aca un modelo mejor al estupido y la diferencia va a ser cuanto mejore. Eso lo normalizo y me da un numero entre 0 y 1. Puede dar menor que 0 O_O. No puede dar mayor que uno. Es 0 cuando el error que genera la recta horizontal pava es igual al error que genera nuestro modelo. Puede dar negativo tanto como yo quiera, pensarlo. Esta metrica la podemos usar para hacer cross-validation, para entrenar, para elegir atributos, etc.\n",
    "\n",
    "## CREO QUE TODO ESTO ESTA REPETIDO\n",
    "\n",
    "### Regresion lineal multiple\n",
    "Ahora vamos a permitir muchas variables. Puede pasar que por ejemplo defina el precio de una propiedad por distintas variables como por ejemplo, la cantidad de colectivos que pasan por ahi, la cantidad de metros cuadrados, la cantidad de pisos, la distancia al subte mas cercano y alguna de estas me de no significativa. Es decir, un p-valor alto. Entonces la puedo eliminar. Me advierte que no le de bola a la variable, no esta aportando nada en este modelo.\n",
    "Notar que cuando analizamos la correlacion de dos variables no vemos causalidad!. Podemos predecir en base a un estimador, que el otro se va a comportar igual. Es todo lo que puedo decir. No lleva una cosa a la otra. Si estados unidos gasta mas en ciencia, no va a haber mas suicidios, no hay causalidad. De ninguna manera estamos haciendo un experimento de que A implica B.\n",
    "\n",
    "### Regresion de polinomios (no lineal)\n",
    "Que pasa cuando los datos no se comportan como una recta? Hacemos regresion de polinomios. La intuicion detras de todo esto es que cuando los $B_{i}$ son 0, cuando vamos poniendo en 0 coeficientes hacemos un modelo cada vez mas simple. Un modelo con mas coeficientes con valores distintos a 0 son mas complejos. Ademas esta la nocion de que cuando son mas chiquitos, un monton de $B_{i}$ con valores muy chicos, me va a dar un modelo mas simple. La regla del pulgar nos dice que valores altos de $B_{i}$ llevan al sobreajuste. Entonces hagamos algo para que sean lo mas bajo posibles. Puede llevarnos a construir mejores modelos. Para esto usamos regularizacion. Lo que hace es penalizar los valores altos de $B_{i}$. En cuadrados minimos veniamos minimizando el error cuadratico medio. Lo que vamos a agregar es un termino mas que penalice los valores altos.\n",
    "\n",
    "Lambda y q son hiperparametros del modelo. Vamos a minimizar toda la ecuacion. Estamos minimizando los residuos (suma de residuos al cuadrado) y le agregamos el termino de la suma de los cuadrados de los coeficientes (cuando q=2 la técnica se conoce como ¨Ridge Regression¨). A la hora de ajustar todo esto vamos a elegir los valores que minimizan los dos al mismo tiempo. Por un lado ajustan el modelo a los datos y por otro lado suelen mantener $B_{i}$ con valores bajitos. El lambda le da un mayor o menor relevancia a las penalizaciones. Para que esto funcione bien hay que tener estandarizadas los valores de las variables de los diferentes ies. Las distintas variables del modelo. Estandarizar es a un valor X restarle la media y dividirlo por el desvio estandar. Lo llevamos a una Normal(0, 1). A todas las variables escalarlas para que sean comparables. Sino lo que pasa es que los valores de los coeficientes dependen directamente de los numeros de la componente correspondiente, entonces queremos poder regularizar bien. No podemos tener peras y manzanas. Todas las variables dentro de la misma escala. Sino no va a hacer nada. Si queremos poder penalizar algunos coeficientes y priorizar otros, queremos todas las magnitudes de cada componente sean comparables (esto lo hace la regularizacion). Todas las $X_{i}$ van a ser comparables ahora.\n",
    "\n",
    "Todo esto, la regresion lineal y la regresion por polinomios, son casos particulares de algo mas general que es el modelo de la generalizacion de regresion lineal (Regresion de funciones base). Usamos una funcion $\\phi$ que toma todos los atributos que tengo en mi set de datos y puede hacer cualquier tipo de funcion sobre estos. $\\phi$ es la función base.\n",
    "\n",
    "Cada funcion $\\phi$ es una funcion definida sobre todas las variables de mi problema. Y todo esto no es otra cosa que transformar el espacio de atributos. Puedo hacer reduccion de atributos teniendo pocos $\\phi$'s, puedo hacer PCA aca adentro, puedo hacer de todo.\n",
    "\n",
    "Porque todo esto se llama como regresion lineal? Porque los coeficientes $B_{1}$, $B_{2}$ y $B_{n}$ estan todos a la 1, son todos lineales. Lo demas son todos atributos. Se puede resolver facilmente con cuadrados minimos. Renombro a cada $\\phi$ como $X_{1}$, $X_{2}$, …, $X_{n}$.\n",
    "\n",
    "## Regresion logistica\n",
    "La regresión lineal no es buena para modelar la probabilidad de ocurrencia de un evento.\n",
    "\n",
    "![title](images/2.png)\n",
    "\n",
    "Si me voy mas para la izquierda me da valores negativos y si te vas mas para la derecha te da mayor que uno! No me esta dando una probabilidad. Entonces usamos una funcion logistica.\n",
    "\n",
    "![title](images/3.png)\n",
    "\n",
    "Vamos a tratar de ajustar la funcion logistica a mis datos. Como la RSS se forma de manera similar, podemos usar tambien la tecnica de minimos cuadrados para fitear el modelo. Es una tecnica muy util para clasificacion. Me da la probabilidad de pertenencia a una clase. Si pongo un umbral en 0.5 lo discretizamos y digo de aca para aca son falsos y de aca para aca verdaderos, entonces es un problema de clasificacion.\n",
    "\n",
    "![title](images/4.png)\n",
    "![title](images/5.png)\n",
    "\n",
    "\n",
    "## Regresion logistica multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Métodos formales para la detección de outliers\n",
    "\n",
    "En la bibliografía se han propuesto una serie de métodos formales para la detección de los mismos. Éstos se pueden agrupar en distintos grupos dependiendo las hipotesis que asumamos:\n",
    "¿Cuál es el modelo que explica la distribución de los datos? Vamos a limitarnos a pruebas que suponen que los datos siguen una distribución aproximadamente normal.\n",
    "\n",
    "Ahora bien, ¿Está la prueba diseñada para un solo outlier o está diseñada para múltiples outliers?\n",
    "Si la prueba está diseñada para múltiples outliers, ¿es necesario especificar exactamente el número de outliers o podemos especificar un límite superior?\n",
    "\n",
    "Las siguientes son algunas de las pruebas de valores más comunes que se utilizan para los datos distribuidos normalmente. Las pruebas dadas aquí se basan esencialmente en el criterio de \"distancia a la media\". Este no es el único criterio que se podría utilizar. Por ejemplo, la prueba de Dixon, se basa en un valor demasiado grande (o pequeño) en comparación con su vecino más cercano.\n",
    "\n",
    "### Prueba de Grubbs:\n",
    "Esta es la prueba recomendada cuando se realiza la prueba de un solo outlier.\n",
    "\n",
    "### Prueba de Tietjen-Moore:\n",
    "Esta es una generalización del test de Grubbs al caso de más de un outlier. Tiene la limitación de que el número de outliers debe especificarse exactamente.\n",
    "\n",
    "### Generalized Extreme Studentized Deviate (ESD):\n",
    "Esta prueba sólo requiere un límite superior en el número sospechoso de outliers y es la prueba recomendada cuando se desconoce el número exacto de outliers.\n",
    "\n",
    "Algo más basico seria utilizar **Z-score**, $Z_i=\\frac{Y_i-\\bar{Y}}{std}$. En otras palabras, los datos se dan en unidades de cuántas desviaciones estándar están de la media.\n",
    "\n",
    "Aunque es una práctica común utilizar Z-scores para identificar outliers, esto puede ser engañoso (particularmente para muestras pequeñas) debido al hecho de que la puntuación Z es como máximo $\\frac{(n-1)}{\\sqrt{n}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje no supervisado\n",
    "Cuando uno no tiene instancias etiquetadas, no puede hacer aprendizaje supervisado. Si queremos hacer algo con esos datos pasamos al modelo no supervisado. La gran estrella aqui es Clustering. Particionamos los datos en grupos cuando no hay categorias/clases disponibles.\n",
    "\n",
    "Solo requiere instancias, pero no etiquetas. Sirve para entender y resumir los datos. Es un paso intermedio para después hacer algo mas.\n",
    "\n",
    "Por ejemplo agarro la pelota verde y veo que son usuarios con mucho gasto pero pocos ingresos. Quiero entender a mis clientes, entonces puedo llamarlos y tratar de entender que es lo que esta pasando. Agarro algunos e investigo. Llamo por telefono y les pregunto cosas. Tal vez ahi encontramos un perfil interesante, por ejemplo son estudiantes, entonces ahora los pude catalogar a todos los de verde como estudiantes.\n",
    "\n",
    "Tenemos datos, hacer mineria en los datos y encontrar informacion interesante.\n",
    "\n",
    "El objetivo de clustering es encontrar grupos de instanicas tales que las instancias en un cluster sean similares entre si, y diferentes de las instancias en otros clusters.\n",
    "\n",
    "AL minimizar la distancia intra-cluster aumento la cohesion, y maximizar la distancia inter-cluster es la separacion.\n",
    "Ejemplos: agrupar genes y proteinas con similar funcionalidad, reducir el tamaño de conjuntos de datos grandes y organizarlos para su mejor visualizacion (ej: lluvias), agrupar documentos para explorarlos mas rapido (ej: google images).\n",
    "\n",
    "Cuando tengo un clustering no es el fin. Tener los grupos no es el fin al que quiero llegar. Es un paso intermedio de un proceso de entender los datos, procesarlos, tomar decisiones mas informadas luego, etc. **Cluster** es un concepto ambiguo!\n",
    "\n",
    "La mejor definicion de cluster depende de la naturaleza de los datos y los resultados deseados. Lo que tenemos son datos sucios, queremos encontrar ciertas agrupaciones de datos que despues van a tener ciertos sentido o me van a ayudar a entender mejor la realidad.\n",
    "\n",
    "## K-Means:\n",
    "Empezamos con datos que estan ahi, todos iguales. Lo primero que vamos a hacer es fijar un K. Es la cantidad de clusters a la cual vamos a apuntar. Poder ir probando variando el K y fijandote los resultados que da. Lo primero que hacemos es fijar dos centroides. Son el centro del cluster. Los tiro al azar al comienzo. Ahora reparto a los puntos en dos cluster. Eso es segun la cercania al centroide. Recalculamos los centroides en funcion de los nuevos cluster que tengo. Tengo 2 cluster y ahora los voy a llevar al punto medio, al centro de masa de los cluster que quedaron definidos. Muevo el centroide del cluster rojo al punto medio de todos sus puntos.\n",
    "Goto 2 hasta que los centroides varien poco\n",
    "\n",
    "Si tengo una masa de puntos rodeados por un anillo de puntos, K-means falla. Uno de los problemas que tiene es que busca cosas globulares, cosas que tengan forma de pelota.\n",
    "\n",
    "## Distorsion del clustering:\n",
    "\n",
    "Lo que vamos a querer es que J sea lo mas chico posible. Lo que tenemos aca es la suma para todas las instancias y todos los cluster vamos a sumar la distancia de la instancia n-esima al centroide k-esimo multiplicado por r_nk que es 1 cuando la instancia pertenece al cluster k y 0 sino. (la suma de distancias al cuadrado de cada instancia a su centroide)\n",
    "\n",
    "Minimizamos J en dos pasos, en el paso 1) vamos a reasignar las pertenencias de las instancias a diferentes clusters. Eso es, en el paso 1 estamos minimizando la sumatoria cambiando los 0 y 1 de pertenencias (el r_nk). En el paso 2) lo minimizamos moviendo los centroides a lugares mas adecuados. Movemos los centroide para que la distancia de las instancias al centroide sea menor, es decir, minimiza J con respecto a los mu_k.\n",
    "\n",
    "Es un ejemplo de EM.\n",
    "\n",
    "* **Ventajas:** Simple, eficiente y general.\n",
    "* **Desventajas:** Hay que especificar K. Sensible a ruido y outliers. Muy sensible a la eleccion de los centroides iniciales, no siempre puede solucionarse con multiples inicializaciones. Solo puede encontrar clusters globulares.\n",
    "\n",
    "Para elegir el mejor K podemos usar métricas que te digan la separación entre clusters y la cohesión entre cada cluster.\n",
    "\n",
    "## Mixtura de gaussianas:\n",
    "Algo un poco mas general que K-Means. Tenemos un cluster gigantesco que tiene su media y su varianza y al lado un cluster chiquitito con una media y una varianza mas chica. Lo que hacemos con kmeans lo unico que tenemos de cada cluster es la media. Ahora con esto vamos a tener la media y la matriz de covarianzas. Vamos a suponer que cada uno de los cluster respeta una distribucion normal. El modelo que vamos a querer construir es para cada una de las instancias ahora yo no quiero la pertenencia univoca a un cluster sino que quiero una probabilidad de pertenencia. \n",
    "\n",
    "Inicializo dos distribuciones al azar. En la foto arranco con dos anillos. No vamos a asignar cada instancia a un unico cluster sino que vamos a asignarle una probabilidad de pertenencia a cada uno de los cluster. El siguiente paso es redefinir las gauseanas. Como se redefinen? Computando sobre todos los datos la media y la matriz de covarianza.\n",
    "El pi le da mas libertad al modelo, lo que hace es a cada una de las gauseanas le asigna una importancia. Puede haber una gauseana que sea mas preponderante que las demas. Una que sea mas absorbente.\n",
    "\n",
    "## Clustering Jerarquico Aglomerativo:\n",
    "Vamos a ir construyendo un dendograma. Arrancamos con un cluster por instancia. Lo que hacemos en cada paso es fusionar los dos clusters mas cercanos. Que es cercano? Hay muchas formas de definirlo. Hago esto hasta que quede un unico cluster. \n",
    "\n",
    "Como definir la distancia entre clusters?\n",
    "La distancia minima entre instancias de cada clusters puede ser una manera. La distancia maxima tambien. Tomar el promedio de todas las distancias posibles del uno al otro. Tambien se puede tomar la distancia entre el punto de masa de cada cluster.\n",
    "\n",
    "Esta elección cambia mucho la forma del dendograma. Tiene sus pro y sus contras respecto de la sensibilidad a ruido y outliers, y a la forma de los clusters que pueden manejar.\n",
    "\n",
    "Es bottom-up este metodo. Existe una version top-down que se llama clustering jerárquico divisivo.\n",
    "\n",
    "* **Ventajas:**\n",
    "No hay que especificar K\n",
    "\n",
    "**Dendograma:** util para crear taxonomias (como la de especies animales)\n",
    "\n",
    "* **Desventajas:**\n",
    "No busca optimizar una funcion objetivo global. Toma solo decisiones locales\n",
    "Cato computacionalmente\n",
    "Sensible a ruido y outliers\n",
    "\n",
    "Por ejemplo el dendograma de los genes, nos muestra que hay dos familias claramente identificadas.\n",
    "\n",
    "## DBSCAN\n",
    "**Density-based spatial clustering of applications with noise**\n",
    "La idea es en vez de buscar globos, romper esa idea y tratar de recorrer los bordes de los posibles clusters. Definimos una vecindad de un punto A, esfera centrada en A y de radio Eps. Y la densidad de un punto A se define como la cantidad de puntos dentro de su vecindad.\n",
    "\n",
    "Vamos a definir 3 tipos de puntos:\n",
    "* **Core points:** puntos con densidad mayor que la constante MinPts.\n",
    "* **Border points:** puntos que no son core, pero son vecinos de algun punto core\n",
    "* **Noise points:** puntos que no son core ni border\n",
    "\n",
    "### Algoritmo:\n",
    "Etiquetar cada punto como core, border o noise\n",
    "Eliminar todos los puntos noise\n",
    "Poner una arista entre cada par de puntos core que son vecinos entre si\n",
    "Cada componente conexa corresponde a un cluster\n",
    "Asignar los puntos border a uno de los clusters vecinos (puede ser necesario desempatar entre 2+ clusters)\n",
    "Complejidad (N = #instancias)\n",
    "tiempo : O(N * tiempo de búsqueda en la vecindad), O(N^2) en el peor caso, O(N log N) si se puede usar k-d trees.\n",
    "Espacio: O(N)\n",
    "\n",
    "* **Ventajas:**\n",
    "No hay que especificar K. Puede encontrar clusters de formas arbitrarias. Es robusto al ruido.\n",
    "\n",
    "* **Desventajas:**\n",
    "Hay que elegir Eps y MinPts. Hay que probar. Puede requerir tener conocimiento de los datos, y ser dificil en casos de alta dimensionalidad.\n",
    "Funciona mal con datos con densidad variable\n",
    "\n",
    "Los cluster que queremos identificar son A, B, C y D. Ahora, el nivel de gris mas oscuro es mas denso. Con constantes bien elegidas puedo elegir el A y el B y todo lo demas es ruido (tapando el cuadrado donde esta C y D). Lo mismo para C y D, si tapo el cuadrado de A y B, puedo identificar con constantes bien elegidas a C y D. CUando corro DBSCAN sobre todo junto con constantes globales, si la densidad del ruido de la izquierda es igual a la densidad de los cluster C y D se me van a escapar como ruido. SI ajusto la constante para poder reconocer a A y B y lo demas como ruido, C y D lo veo como ruido. Ahora si ajusto las constantes para reonocer C y D, todo el cuadrado de la izquierda va a ser un unico cluster.\n",
    "Esto se debe a que los parametros son globales. Pero yo cuando me tiran las nubes de puntos no tengo idea de las densidades y como estan formados. Complicado…\n",
    "Si haces un grid search para los parametros, quiza para una combinacion de parametros te aparecen como cluster A y B y para otra C y D y te podes ir dando cuenta mas o menos que onda.\n",
    "\n",
    "## Evaluacion de clusters\n",
    "En clasificacion y regresion, como tenemos los target podemos dividir en set de entrenamiento y test y bajo alguna metrica ver cuanto error tengo. Aca no tengo nada de eso.\n",
    "\n",
    "* **Matriz de similitud:**\n",
    "Es una matriz cuadrada y simetrica que tenemos las instancias. En cada uno de los casilleros vamos a poner un valor entre 0 y 1 con la similitud entre pares de instancias.\n",
    "\n",
    "Tenemos una funcion de similitud definida en el dominio. Lo interesante de esto es ordenar esta matriz segun los cluster llegado a una cosa asi. Al ordenar las filas y columnas segun el cluster de las instancias, el clustering es bueno si la MS es diagonal por bloques.\n",
    "\n",
    "Lo que deberia pasar si el cluster es bueno, es que dentro de un mismo cluster, las instancias de un mismo cluster se parecen entre si. Nos va a mostrar que los cluster tienen instancias similares, cierta cohesion. Y ademas son distintas al resto.\n",
    "\n",
    "Otra manera es una forma numerica que nos va a tratar de capturar la cohesion (cuan relacionados entre si estan los elementos de un mismo cluster) y la separacion (cuanto se separan los clusters). Esto lo vamos a lograr con el coeficiente de Silhouette.\n",
    "\n",
    "* **Coefiicente de Silhouette:**\n",
    "Para cada punto vamos a calcular la distancia media de ese punto a los de su cluster. Esto es a.\n",
    "Ahora calculamos b que es la distancia media a todos los puntos de los otros cluster y me quedo con la minima. Calculo las distancias medias del cluster 1, del cluster 2, y me quedo con la minima.\n",
    "En un clustering bueno b deberia ser mucho mayor que a. Eso es lo que queremos calcular. Ese es s.\n",
    "\n",
    "Lo que se ve es que los puntitos que estan dentro de un cluster, bien adentro, tienen buen coeficiente de silhouette y a medida que se acercan a la frontera son mas oscuros, ya que no tienen bien definido su pertenencia. Una vez que tengo estos numeritos que son por instancia, uno puede calcular un valor para todo un cluster y tener en un solo numerito que nos diga si es bueno el cluster o no. Ese numerito es una combinación de separacion y cohesion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje por refuerzos:\n",
    "Perro de pavlov. Le daba carne y veia que salivaba. Siguiente experimento dijo, si el perro saliva al ver la carne, hay una consecuencia de ver la carne, que pasa si yo cada vez que le doy de comer toco la campanita? Asi lo hizo sobre cierto periodo de entrenamiento y despues ve que al tocar la campanita, el perro saliva sin que este la carne. El tipo lo que hizo fue hacer que dos estimulos separados que no tengan nada que ver, asociarlos para que despues cuando toque la campanita genere el efecto del otro evento asociado. Condicionamiento pavloviano.\n",
    "\n",
    "Con el tiempo siguieron haciendo este tipo de experimentos. Ponen a una rata que tiene un auricular. Cuando suena ven cuanto se congela, se queda quieta paralizada. En la etapa de habituacion al principio hay un pequeño porcentaje de ratas que al sonido se quedan paralizadas. El sonido en si no hace nada, no tiene ningun efecto. Ahora ademas de dar sonido, se los electrocuta un poquito. Rapidamente la rata aprende que cuando viene el tono se viene la electricidad. Van entendiendo que tono significa todo mal. Despues viene la etama de extincion que solo se reproduce el tono. Se ve que al principio de esta etapa cuando suena el tono se paraliza pensando que la van a electrocutar. A lo largo del tiempo esto baja y desaprende. Vuelve a entender que no pasa nada con el sonido.\n",
    "\n",
    "El cerebro de estos seres es plastico y se pueden ir adaptando dependiendo del entorno. Esta todo el tiempo aprendiendo y reaccoinando ante el entorno.\n",
    "\n",
    "Aca no hay ningun tipo de toma de decisiones. Hay relaciones estimulo-respuesta sin ningun tipo de control. Vamos a querer agregar el control para tomar decisiones. Tomar una accion y tener algun tipo de respuesta. Tienen consecuencias las acciones.\n",
    "\n",
    "Thorndike hizo un experimento con gatos y creo lo que se llama ¨curva de aprendizaje¨. Agarro gatos y los puso adentro de una jaula. Gatos con hambre. Estas cajas tenian que hacer ciertas cosas, como meter la manito y levantar algo, etc. Alguna estrategia habia que aplicar para salir de la caja. En los primeros intentos se ve que tardaban bastante tiempo en segundos. El gato se va capacitando. En las primeras etapas aprende como salir de la caja. El gato toma decisiones y fue aprendiendo a salir lo antes posible de ahi. En la vez numero 30 ya sabe como es la estrategia para salir. Aca vemos que los animales pueden aprender comportamientos arbitrarios.\n",
    "\n",
    "Modelo de aprendizaje guiado por errores: el cambio en el valor de una asociacion es proporcional a la diferencia entre nuestra prediccion y lo observado\n",
    "\n",
    "![title](images/refuerzos/1.png)\n",
    "\n",
    "R es el valor de una asociacion entre dos cosas, salivar y ver un churrasco, hacer la estrategia y salir de la jaula, etc. Al valor nuevo va a ser lo que yo sabia antes mas un learning rate y un error. Este error es el valor riesgo y el valor viejo. El valor riesgo es lo que vamos a llamar recompensa.\n",
    "\n",
    "La forma que aprendemos no es inmediata, lleva tiempo.\n",
    "\n",
    "Aprendizaje por refuerzos. Tenemos un agente (por ejemplo un robot), que tiene sensores para observar el estado de su entorno. La definicion de estado la damos nosotros, por ejemplo, todo lo que ocurre a nuestro alrededor. Vamos a tener acciones, cada accion que haga probablemente va a modificar el estado. Cada accion conlleva a una recompensa inmediata (cero, positiva o negativa). Estos son los elementos que necesitamos para hablar de aprendizaje por refuerzos. \n",
    "\n",
    "![title](images/refuerzos/2.png)\n",
    "\n",
    "Es un loop infinito, va a ir todo el tiempo ciclando.\n",
    "El objetivo es que el agente aprenda una estrategia o politica de control para elegir las acciones que maximicen las recompensas. Que se desempeñe de manera inteligente. Pi es una politica que es una funcion que dado un estado elige una accion.\n",
    "\n",
    "![title](images/refuerzos/3.png)\n",
    "\n",
    "SI yo tengo un estado, tomo un accion y gano una recompensa tiene mucha pinta a una regresion, o clasificacion. En si a algo supervisado. Estoy tomando decisiones y despues me dicen si estuvo bien o mal. Para dejar en claro que esto no es aprendizaje supervisado vamos a ver las diferencias:\n",
    "\n",
    "Las recompensas vienen o pueden venir con demora, es decir, por ejemplo ganar un juego de ajedrez quiza uno pueda ver internamente las mejoras localmente pero asi no funciona este paradigma, la recompensa viene al final de todo cuando ganaste el juego y ahi tenes que poder ser capaz de recompensar las acciones anteriores, darle distintos pesos en funcion de haber ganado. Entonces esa nocion de ver a cada decision como un problema de clasificacion se pierde, porque la clasificacion tendria que tener ya la recompensa. No existe esa nocion de planificar. Otra cosa importante es que en el caso del robot que va por ahi aprendiendo, los datos de entrenamiento los determina el robot mismo. Si al robot se le canta explorar por aca y se choca con una pared, esas decisiones, esos datos de entrenamiento son basados en la propia estrategia del robot.\n",
    "\n",
    "El formalismo estandar para modelar a estos agentes se conoce como un proceso de decision de Markov. Tenemos un conjunto de estados S (lo que observa el robot o el agente). No necesariamente es facil de definir. Cuando es muy dificil definir que es un estado, se usan redes neuronales para facilitarlo. La definicion de S puede ser complicada. Tenemos tambien un conjunto de acciones A (que cosas puede hacer el robot). Una funcion de transicion, que toma un estado actual y una accion y nos dice a que estado caigo. Y tambien R una funcion de recompensa, que agarra un estado y una accion y me da un real que es la recompensa. Si fuera un proceso de markov de orden 2 la funcion de transicion tomaria dos estados y me diria a cual ir.\n",
    "\n",
    "Lo que queremos es definir una poitica Pi que va del conjunto de estados al conjunto de acciones. Es lo queremos que aprenda. Tiene que ser una funcion.\n",
    "\n",
    "Funcion de valor: Para alguna politica dada, va a ser una funcion que a cada estado, a un estado le va a asignar algun valor. Va a determinar cuan valioso es ese estado segun la politica. En el mundo grilla, los estados mas cercanos al Goal van a ser mas valiosos porque estan mas cercanos de obtener una recompensa. Saber cuan valioso es cada uno de los estados de S. Voy a decir que el valor de St (estado) es la recompensa inmediata R_0, la recompensa por la primera accion. Despues viene la recompensa R_2, y asi sucesivamente. Esto es si yo quisiera darle el mismo peso a todo el camino de recompensas que tengo hasta el final. Es una opcion. Pero algo mas general es multiplicarlos por gamas. Es el factor de descuento (va entre 0 y 1). Es un hiperparametro del modelo.\n",
    "\n",
    "![title](images/refuerzos/4.png)\n",
    "\n",
    "V(s_t) es el valor acumulado que se consigue al seguir la politica pi a partir del estados_t. La idea es tomar acciones que te lleven relativamente pronto al Goal.\n",
    "\n",
    "![title](images/refuerzos/5.png)\n",
    "\n",
    "Podemos definir entonces el valor de un estado como la recompensa inmediata mas el valor del siguiente estado. Ahora con esta definicion recursiva, el objetivo es aprender la mejor politica posible dado un problema. Esa politca optima va a tener asociada los valores optimos. Queremos aprender los valores optimos, V*. Despues en funcion de eso vamos a poder elegir una politica.\n",
    "\n",
    "![title](images/refuerzos/6.png)\n",
    "\n",
    "Algoritmo 1: Value Iteration\n",
    "\n",
    "![title](images/refuerzos/7.png)\n",
    "\n",
    "Value iteration requiere conocer el modelo: S, A, R y T. Definimos politicas cuando tenemos todo el mapa conocido. Es un algoritmo ¨model-based¨ porque necesita conocer todo el modelo. Esto en la mayoría de los casos no tiene sentido. Si pongo un robotito en la nada, no sabe los estados, ni las transiciones, ni las recompensas.\n",
    "Necesitamos un metodo que no necesite conocer todo el modelo. Q-learning.\n",
    "\n",
    "El objetivo como dijimos es aprender la funcion de valor optima. La formulacion que hicimos antes tiene cosas que dependen mucho de R, V, S. Vamos a tratar de independizarnos de calcular el V* directamente para tener la politica mejor y vamos a definir lo siguiente.\n",
    "\n",
    "![title](images/refuerzos/8.png)\n",
    "\n",
    "A lo que estamos maximizando lo llamamos Q(s,a). Eso dicho en español es la maxima ganancia esperada a partir de un estado ejecutando la accion a. Para poder hacer esta cuentita necesitamos conocer a R de antemano. Necesito saber si estoy parado aca, quiero evaluar la posibilidad de hacer una accion, quiero ver cuanto reward me da. Eso es el conocimiento del modelo. Saber a donde te llevaria, cuanto te garparian, por cada accion. Ademas se el conjunto de estados. Pero ahora queremos saber casi nada del modelo.\n",
    "\n",
    "Con esto lo que logre es simplemente escribir a Q(s,a) independizandome del modelo. El gran problema de este metodo es la convergencia.\n",
    "\n",
    "Lo que esta pasando es que para saber cual es el valor de una accion, ejecuto la accion y me fijo cual es el reward y despues maximizo sobre los Qs del nuevo estado.\n",
    "\n",
    "Para contextualizarlo, el robotito toma una accion y le llega una recompensa. El en el estado en el que esta parado sabe que acciones puede tomar pero no sabe que recompensas le va a dar cada accion. Si lo supiera entonces conocería R.\n",
    "\n",
    "![title](images/refuerzos/9.png)\n",
    "\n",
    "Las politicas pueden ser elegir el mejor Q que tenga, la accion mejor que tenga segun el modelo actual, y otra podria ser a veces elegir al azar, a veces la de mejor ganancia, etc. Hay diferentes formas de elegir.\n",
    "El gama es cuanto se penalizan las ganancias que vienen despues y cuanto se priorizan las ganancias inmediatas con respecto a las que vienen despues. Las ganancias inmediatas las vamos a usar de una, las que vienen despues las podemos ponderar con 0.9.\n",
    "\n",
    "Alfa es cuan rapido aprendemos. Este es el valor nuevo de Q(s,a). Si la tasa de aprendizaje es 0 no aprendo nunca nada. Con alfa 1 aprendemos demasiado rapido, no confiamos en la experiencia. Nos quedamos solo con lo que vimos recien, no confiamos en el pasado. QL no requiere conocer el modelo (model-free).\n",
    "\n",
    "Algoritmo 2: Q-Learning\n",
    "\n",
    "![title](images/refuerzos/10.png)\n",
    "\n",
    "Dilema exploracion-explotacion: cuando explorar mejores opciones, cuando explotar lo que ya sabemos. K-armed bandits, tenemos k maquinas tragamonedas y una cantidad de fichas a jugar, tenemos que estimar las probabilidades de cada una entonces vamos explorando y jugamos 10 fichas en una, 10 fichas en otra y voy armandome una tablita de probabilidad de ganar en cada maquina para tratar de encontrar la que mas ganancia me da.\n",
    "Veamos algunas estrategias para elegir las maquinas:\n",
    "Estrategia epsilon-greedy: con probabilidad epsilon vamos a elegir al azar. Por ejemplo con 10% vamos a decir que el 10% de las veces elijo las maquinas al azar y el 90% de las veces elijo la mejor maquina conocida hasta el momento.\n",
    "\n",
    "![title](images/refuerzos/11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento del Habla\n",
    "**Objeto de estudio**: Habla.\n",
    "\n",
    "**Que es el habla?** Audio. La vamos a interpretar como una onda.\n",
    "\n",
    "## Tres elementos fundamentales en el procesamiento del habla:\n",
    "* Reconocimiento automatico (hablo y la computadora reconoce las palabras, lo que hace despues es otro problema). Es el mas conocido. \n",
    "* Sintesis de habla es lo opuesto, yo escribo algo y la computadora lo lee.\n",
    "* Detectores de caracteristicas del hablante (vamos a tratar de a partir de una senial saber si la persona es un hombre o mujer, la edad, etc.)\n",
    "\n",
    "## Reconocimiento automatico: \n",
    "Habla -> secuencia de palabras. Tenemos una senial de audio proveniente de una grabacion. Al audio lo vamos a representar de alguna manera.\n",
    "\n",
    "El audio son fluctuaciones de presion que generaron el habla (el medio sería el aire). Una manera de poder visualizar dichas fluctuaciones son mediante un **Espectograma**. El eje X es el tiempo y el eje Y son las frecuencias. **Nos muestra las frecuencias presentes en el habla**. Por ejemplo de 0 a 5000 hz. Los manchones son diferentes frecuencias presentes en el habla. El reconocimiento del habla se encarga de reconocer patrones en este espectro de frecuencias en el tiempo que se corresponden con distintas letras, fonemas. La s tiene un valor particular (ruido blanco). El ruido blanco no tiene ninguna frecuencia presente, todo desparramado al azar. La a tiene 4 formantes por ejemplos (4 manchones). En un instante de tiempo podemos ver que hay más de una frecuencia presente. Negro es que esa frecuencia esta con energia alta. Muy presente en la senial. Cuando decimos manta podemos estirar la a diciendo maaaaaanta, pero estirar la t cagamos la fruta. Lo que no es estirable es porque la t es como un golpe. Lo generamos con un flujo muy breve de aire por la boca. La t la b la d la g no se pueden estirar en el tiempo. Hay que ver tanto la presencia de frecuencias como la evolucion temporal.\n",
    "\n",
    "A la senial hay que limpiarle el ruido, preprocesarla, etc. Todo esto es ing electronica. Tambien hay que segmentar los hablantes, la senial. De aca a aca esta hablando pepe y de aca a aca el pepo. No es nada trivial pasar de una secuencia de palabras (habla) a una secuencia de texto legible. Una vez que tenemos las palabras queremos poder hacer algo con esto. Por ejemplo generar una consulta a una base de datos o entender que me quieren decir.\n",
    "\n",
    "## Sintesis: \n",
    "Dado una secuencia de palabras quiero generar audio. Si yo llamo al 113 algo lee la hora y me lo dice oralmente. Por ejemplo se guardan los 24 valores desde 20 horas, 21 horas, etc y se van concatenando (sintesis concatenativa) con los de minutos. Si achicamos la unidad que usamos (donde corto) es mejor. Podemos decir mas cosas, generar mas cosas. Lo que se usa hoy en dia son **difonos**. Partis de la mitad de un sonido (**la parte estable de un sonido**) y vas hasta la parte estable del siguiente sonido. Tenemos una base de datos que para cada uno de estos pares de sonidos tenemos varias instancias, por ejemplo 4 instancias de la a. Como vamos concatenando? Generamos una secuencia que minimice las penalidades (como se pegotean los audios, puede ser que queramos decir hola mundo muy enfática entonces agarramos los difonos alegres, etc.) \n",
    "\n",
    "* **Problema:**\n",
    "Todo lo que investigas para el espaniol no se pueda usar en otro lenguaje, o que con el tiempo el mismo lenguaje vaya cambiando. Nuevas frases, etc. Toda la teoria de un lenguaje suele cambiar.\n",
    "\n",
    "* **Sintesis basada en formantes:** \n",
    "Es tratar de generar el habla con una caja negra. No trata de simular el tracto vocal y todas las cosas fisicas que ocurren sino directamente yendo al punto. Que hay que generar? Esta onda con esta caracteristica? Entonces dejame dibujartela y esto va a sonar como vos queres. \n",
    "\n",
    "* **Sintesis basada en HMMs:**\n",
    "Se usa para reconocimiento del habla, cuando uno entrena esos modelos crea tambien un modelo generativo. Sirve para describir datos y para predecir pero tambien se puede dar vuelta y generar. Conociendo la secuencia de fonos que quiero generar, generame los espectogramas correspondientes. Es un modelo estadistico, no hay grabaciones como en sintesis concatenativa (esta atado a lo que grabo, solo puedo recortar y pegar). Podes cambiarle el tono de voz, la velocidad, etc.\n",
    "\n",
    "Si me dicen 110 no se si decir ciento diez o uno uno cero.\n",
    "\n",
    "* **Sintesis articulatoria:**\n",
    "Trata de simular mediante tubos el tracto vocal usando la fisica.\n",
    "Si queremos trabajar para reservar vuelos por ejemplo, tengo que pasar el habla a una consulta SQL y decirle si queda o no lugar.\n",
    "\n",
    "## Acustica:\n",
    "El sonido son fluctuaciones de presion en el medio causadas por fuentes (un instrumento musical, etc) y llegan al oido. Es el encargado de estas fluctuaciones transformarlas en lo que nosotros interpretamos como sonido. \n",
    "\n",
    "Ejemplo para entender la propagacion de una onda: tenemos un monton de particulas esperando en una cola de banco. Cuando uno se va, tiene un vacio adelante y pum se va para adelante. Todos los de atras de el tambien se van para adelante, el vacio se propaga en el medio. Si uno empuja a otro (le aplica una variacion de presion) ese otro se va a llevar por delante al siguiente y asi. Ojo que se va disipando la onda expansiva. En algun momento dejo de empujar al siguiente. Ejemplo de los vasos con el piolin tenso! Esta variacion en la presion es un solo numero, lo que viaja es un numerito nada mas! Entonces con ese numero ya tengo todo para representar al sonido. En la pc tengo que ver como samplearlo (muchas veces por segundo ya que pasan miles de veces por segundo). Tenemos que medir esas fluctuaciones. Cada un rango de tiempo tomo una muestra y la dibujo. Eso es lo unico que necesito para grabar. La gracia de esto es que se puede descomponer en un monton de frecuencias. Esta senial se puede estudiar en mas detalle. \n",
    "\n",
    "Los sonidos se pueden descomponer en **periodicos o aperiodicos**. \n",
    "* **Ondas periodicas simples o senoidales:**\n",
    "Son la piedra fundamental de la acustica. Una onda senoidal es sin(x). Da un tono puro, cuanto mas alta es la frecuencia mas agudo se escucha.  Ciclo es hasta donde repito, periodo es la duracion del ciclo. La frecuencia es 1/periodo. Estas ondas senoidales se pueden combinar y generar ondas complejas. Las ondas simples se pueden sumar. \n",
    "* **Ondas complejas:**\n",
    "Es una onda ciclica formada por la suma de un monton de funciones senoidales. Cada una con distintas caracteristicas. Por ejemplo con dos senoidales de 100 y 1000 hz.\n",
    "Los sonidos aperiodicos no tienen un patron, no podemos hablar de frecuencia ni de ciclo. Nada que se repita. Vamos a hablar de dos tipos, ruido blanco (fluctuaciones aleatorias de presion) no hay informacion, no sirve de nada. A nosotros nos interesa porque aparece en la S y en la F. Y ondas transitorias.\n",
    "\n",
    "* **Sonidos aperiodicos:**\n",
    "**Ruido blanco:**\n",
    "Fluctuacion aleatoria de presion. El espectro es plano, igual amplitud para todas las frecuencias.\n",
    "**Ondas transitorias:** \n",
    "Fluctuaciones subitas de presion que no se sostienen ni se repiten. Portazos, disparos, mouse clicks, [p] [t]\n",
    "\n",
    "## Interpretacion de ondas:\n",
    "**Analisis de fourier:** lo que hace es agarrar la onda (por ejemplo una compuesta) y decirnos que frecuencias estan presentes en esa onda y la amplitud de cada frecuencia presente. Nos da una estimacion. Esto es el espectro energetico en un punto o intervalo de tiempo. Lo vamos a usar para el espectograma. El espectro es una linita en el espectograma. El espectrograma es una descomposicion de la longitud de las frecuencias en el tiempo. El habla entra entre 0 y 5 khz. Puede ser que en una ventanita encuentre cierta periodicidad en un sonido aperiodico, pero lo que me define la aperiodicidad es que no la puedo extender en el tiempo.\n",
    "\n",
    "## Seniales:\n",
    "La senial en el mundo real es analogica. Es continua tanto en el tiempo como en amplitud de la onda. Pero necesitamos mudarnos a un mundo discreto. Ambas componentes hay que discretizar. El tiempo sampleamos cada cierto intervalo. La conversion analogica digital tiene por un lado el muestreo que discretiza el tiempo que me define el sampling rate, cuantas veces por segundo voy a tomar muestras. Por el teorema del sampleo, tengo que samplear a mas del doble de la frecuencia. Cuantización: para la amplitud hay que definir cuantos bits vamos a usar. Un int? Un long? Se usan 16 bit en general.\n",
    "\n",
    "* **Amplitud:** \n",
    "Maxima variacion de presion por sobre la presion atmosferica normal.\n",
    "\n",
    "* **Fase:** \n",
    "Timing de la forma de onda relativo a algun punto de referencia.\n",
    "\n",
    "* **Ondas periodicas complejas:** \n",
    "Ondas ciclicas formadas por multiples ondas senoidales\n",
    "\n",
    "* **Muestreo (sampling rate):** \n",
    "Discretizacion del tiempo\n",
    "\n",
    "* **Cuantizacion:** \n",
    "Discretizacion de la amplitud\n",
    "\n",
    "* **Saturacion digital (clipping):** \n",
    "La amplitud de la senial es mayor al rango representable.\n",
    "\n",
    "* **Frecuencia fundamental (F0):** \n",
    "Frecuencia mas baja de una onda periodica (patrón complejo mas chico).\n",
    "\n",
    "* **Metodo de autocorrelacion:** \n",
    "Deslizar una copia de la onda hacia la derecha, hasta encontrar un punto de maxima correlacion. El offset encontrado corresponde a la duracion del periodo (T). La inversa (1/T) es la F0.\n",
    "\n",
    "* **Funciona bien:** \n",
    "Para fonos sonoros: vocales [m] [b] [l] (ondas periodicas compuestas)\n",
    "\n",
    "* **Funciona mal:** \n",
    "Para fricativas, oclusivas sordas, etc. [s][f][t][k][tsigma] (sonidos aperiodicos)\n",
    "\n",
    "Algo copado, la diferencia entre 200 y 300 mhz es mucho mas grande que de 1200 a 1300 mhz. Parecen sonidos que estan igual de separados pero los notamos totalmente distintos. No es lineal nuestra percepcion de acuerdo a como sube y baja la onda en un intervalo de tiempo. Hay una escala que es logaritmica, escala MEL. Es una escala mas cercana a nuestra forma de percibir las diferencias de tonos en distintas partes del espectro. \n",
    "\n",
    "## Tono:\n",
    "Lo que le da el tono a una onda es la cantidad de veces que le pegamos al timpano por segundo.\n",
    "\n",
    "El microfono convierte estas osilaciones de presion en el aire en osilaciones de voltaje. Transforma esos cambios de presion en voltaje. Se puede guardar directamente en manera analogica estos voltajes. La PC lo que hace es convertirlo en 1s y 0s. El muestreo es la discretizacion en el tiempo y la cuantizacion es la discretizacion de la amplitud. La primera pregunta que aparece es cada cuanto hay que tomar muestras en la senial. El teorema de Shannon. Si tenemos una onda con frecuencia f, necesitamos una tasa de muestreo mayor que 2f. Necesitamos poder medir una parte de la onda que sube y una parte de la onda que baja. Sino no estariamos capturando la periodicidad de una funcion. Si hago exactamente el doble puedo caer en los 0s de la funcion periodica =(. Lo que queremos siempre es poder grabar algo. No queremos usar todas las frecuencias posibles porque reviento la memoria. Usar lo menos posible, la frecuencia mas baja posible que me permita capturar lo que queramos capturar.\n",
    "\n",
    "Queremos muestrear la mayor cantidad posible guardando lo menor posible. Para habla tambien neceitamos 44 khz? No amigo. La empresa bell eligió 8Khz. Hay problemas con el habla, la S y la F se complican! La S tiene frecuencias mas altas! 16 Khz anda barbaro para habla. Podriamos capturar hasta 8khz pero en habla casi no hay frecuencias presentes arriba de los 6 Khz.\n",
    "\n",
    "* **Aliasing:** \n",
    "Ocurre cuando la senial contiene frecuencias mayores a la frecuencia de sampleo, por ejemplo cuando en la ruta vemos las ruedas de los autos yendo a mas de 100 km/h. Tenemos una frecuencia de sampleo que no alcanza para capturar la periodicidad de la onda (de la rueda girando, de la turbina, etc).\n",
    "\n",
    "A veces cuando grabamos hay frecuencias altisimas que ni escuchamos pero el microfono si! Es una onda que se le agrega al audio. Una frecuencia que no deberia haber estado (por ejemplo una frecuencia supersónica). Y cuando la escuchamos hay un ruido muy agudo. Esta habiendo aliasing. Seniales fantasmas que eran otra cosa en la vida real. La solucion a esto es un filtro anti aliasing. Yo te pido que me grabes a 8 Khz pero internamente graba a todo lo que le de y filtra las frecuencias mas altas y me da las frecuencias dentro del rango que yo quiero.\n",
    "\n",
    "Los filtros tienen 3 sabores, los pasa bajos, pasa altos y los pasa banda. Es bloquear las componentes mayor a un umbral, menor o fuera de una banda.\n",
    "\n",
    "Veamos otro tipo de problema que se puede presentar:\n",
    "\n",
    "La cuantizacion es otro de los origenes de errores. Aliasing viene de la discretizacion del tiempo. Cuando discretizamos la amplitud, la energia hay que ver cuantos bit dedicarle a esto. Cuantos niveles es necesario distinguir es a prueba y error. Llevamos una curva a algo escalonado.\n",
    "\n",
    "* **Saturacion digital (clipping):**\n",
    "La amplitud de la senial es mayor al rango representable. Para solucionar esto se puede redefinir los niveles de amplitud o disminuir la amplitud de la fuente (le pido a la persona que baje el microfono).\n",
    "\n",
    "## Variables acusticas que se pueden medir:\n",
    "* **Intensidad:**\n",
    "Intensidad: la onda es mas grande cuando hablo mas fuerte, la presion es mayor. Eso quiere decir que la amplitud de la onda es mayor donde grito mas. Eso es lo que quiero medir cuando vea intensidad. Quiero capturar esa amplitud, no punto a punto sino en una palabra. En la palabra hola, la primera silaba comparada a la segunda, cual pronuncio con mas intensidad. Mido cuan fuerte fue la fluctuacion en el aire. Se puede medir en Pascales, el microfono puede medirlo en Voltaje, aunque lo mas comun son los decibeles (es una escala bastante particular ya que es una comparacion, no es una unidad de por si. Los voltios, centimetros, son todas unidades absolutas. Los decibeles son una comparacion del estilo, comparo contra el silencio. 20 log (p / p0) db, agarro la presion en pascales, la divido por el silencio. Me lo lleva a magnitudes manejables. Divido fluctuaciones de presion, no presiones.) \n",
    "\n",
    "Volumen, amplitud, energia, intensidad, para nosotros es todo lo mismo.\n",
    "\n",
    "Para calcular intensidad lo que hacemos es, tomamos N muestras de amplitud de una senial. Y lo que hacemos para calcular la RMS la norma solo que a los xi los divido por N. Esto nos  queda en una unidad de medida, entonces lo dividimos por P0 que es el nivel de referencia del silencio le aplicamos log10 y multiplicamos por 20.\n",
    "\n",
    "Cuando grite o susurre voy a ver cambios en la intensidad, en los decibeles.\n",
    "\n",
    "* **Tono de voz:**\n",
    "Tambien conocido como **Nivel Tonal** (Pitch, es la altura de la senial, si suena aguda o mas grave).\n",
    "**Frecuencia fundamental (F0)** es la frecuencia mas baja de una onda periodica (la mas larga). Buscar el patron complejo mas chico. Una vez que tengo el ciclo fundamental, tengo que ver a cuan frecuentemente se repite. Si el patron se repite muchas veces y muy rapido tengo algo mas agudo. Ver cuan frecuentemente se repite es calcular el Pitch Tracking. Como se hace esto? Hay muchas formas, el mas comun y que mejor resultados da es el metodo de auto-correlacion. Si dos ondas se comportan parecido van a tener una correlacion cercana a 1, sino mas cercana a -1 si es lo opuesto. Con 0 es que no tienen nada que ver. Entonces lo que hacemos aca es partir de la base que una onda periodica se relaciona consigo misma porque cada ciclo se parece mucho al ciclo siguiente. Cada uno de estos ciclos por deficion se parece mucho al que viene despues. Si agarro y deslizo una copia de la onda para la derecha en algun momento voy a matchear. La auto correlacion de la senial consigo misma va a tener un punto maximo cuando llegamos al primer ciclo. Deslizo la ventana hasta encontrar un punto de maximo correlacion. Cuando encuentro ese punto encontre el periodo divido 1/periodo y tengo la frecuencia fundamental. Como se cuando parar? Si empiezo a seguir encuentro mas puntos, tengo muchos pitch. \n",
    "\n",
    "* **Errores de halving y dalving:**\n",
    "Le pifiamos por el doble o por la mitad al pitch. Puede ser que la senial sea muy parecida a mitad de camino y tenes otro pico de correlacion. Puede ser que si te da un valor de pitch de 500 hz y el que habla es alguien con una voz muy grave se que nunca puede tener 500 hz de pitch, de los candidatos que tenia me quedo con el mas grave. Con el metodo de autocorrelacion podemos ir midiendo instante a instante (pitch track). Esto esta fuertemente relacionado al nivel tonal.\n",
    "\n",
    "Los armonicos son multiplos de la frecuencia fundamental (armonicos de la guitarra, del saxo, etc).\n",
    "\n",
    "Esto funciona muy bien para fonos sonoros (todos los sonidos que producimos en los cuales vibran las cuerdas vocales). La b vs la p es que vibran las cuerdas vocales, la p hace todo lo mismo pero no vibran las cuerdas vocales (todo en el tracto vocal es lo mismo). Las consonantes sordas son las que tienen problemas para el pitch tracker, porque producen o bien ruido blanco o sonidos transitorios (todos los tipos de sonidos aperiodicos). Si no tengo periodicidad como encuentro un patron? El metodo de correlacion va a fallar. Y peor, si tenemos mala suerte nos puede dar cualquier fruta!."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linguistica:\n",
    "\n",
    "* **PRAGMATICA** (son las intenciones de lo que decimos)\n",
    "* **SEMANTICA** (estas oraciones tienen una interpretación o significado)\n",
    "* **SINTAXIS** (las palabras se juntan para formar oraciones. Aca tengo una gramática que me permite armar estas oraciones)\n",
    "* **LEXICO** (a partir de los fonemas, armo las palabras del lenguaje)\n",
    "* **FONOLOGIA** (como agrupamos estos fonos, fonemas, alofonos = fonos hermanos)\n",
    "* **FONETICA** (como se agrupan estos sonidos, fonos)\n",
    "* **ACUSTICA** (esencialmente el sonido)\n",
    "\n",
    "Ahi en la pragmatica juega mucho la prosodia, la prosodia va medio en paralelo con todo esto a partir de la fonologia porque lo modifica. Puede modificar la palabra que decimos, la secuencia de sonidos puede ser tambien otra (pasa en chino). La prosodia puede hacer que la misma sintaxis tenga diferente semantica.\n",
    "\n",
    "Fonetica y fonologia son un conjunto de disciplinas. Con lo de buba y kiki ya en el sonido mismo tenemos significado! \n",
    "\n",
    "No descuidemos a la fonetica.\n",
    "\n",
    "Fonologia tiene mas que ver con el uso de la fonetica para el lenguaje. \n",
    "\n",
    "## Fonetica:\n",
    "Es el estudio de los sonidos del habla, que puede ser independiente del lenguaje. Son los sonidos que producimos en el tracto vocal y puede ser relacionado con el lenguaje o independiente.\n",
    "Hay muchas maneras de decir la Y. En lluvia lo pueden decir de al menos 4 maneras.\n",
    "\n",
    "Como se producen los sonidos del habla? Esto va desde los pulmones hasta los labios. Cuando hacemos vibrar las cuerdas vocales formamos las vocales. Es simplemente aire fluyendo y haciendo vibrar las cuerdas vocales.\n",
    "\n",
    "Las cuerdas vocales cuando estan sanas permiten vibrar y generar un tono bastante puro. Podemos modificar la frecuencia y cambiar el nivel tonal. Si no hacemos vibrar las cuerdas vocales hacemos sonido sordo, hablar susurrando. O generamos una fuente sonora o una sorda, la sorda es ruido blanco (una aspiracion). Todo a partir de las cuerdas vocales para arriba lo usamos como filtro para modificar (epiglotis, velo del paladar, etc). Vamos a crear alguna taxonomia que nos permita replicar la produccion de sonido.\n",
    "\n",
    "La categoria obvia son las **vocales vs consonantes**. Motivacion mas linguistica que fonetica. La m tiene mucho mas de vocal que de consonante, la unica diferencia en decir A o M es que cerramos la boca. Las vocales son casi siempre sonoras, dejamos fluir el aire y poner pocas restricciones en el resto del tracto vocal. Todos los sonidos a nivel fonetico los escribimos entre []. Los fonos son []. Las consonante tienen cierta restriccion en el flujo del aire. La restriccion de vocales es poca, consonantes un poco mas. Esto es independiente del lenguaje (la fonetica), de chiquitos aprendemos algun conjunto de categorias foneticas. Eso no quita que lo que vos reconoces como una S esta robandole sonidos a otro lenguaje. Estos fonos son agrupaciones de sonidos independientes del lenguaje. En espaniol tenemos dos casos muy lindos que son las semi. Semivocales, reino, causa. Se escriben igual [i] [u] pero aparecen mas apagadas. Lo podemos ver en el espectograma. Semiconsonantes: [j] hielo, [w] cuando.\n",
    "Hierba, yerba, gg bro.\n",
    "\n",
    "* **Vocales: son todas sonoras**\n",
    "\n",
    "### Taxonomias de las vocales:\n",
    "**Apertura o altura (cuan alta esta la lengua):**\n",
    "* Abierta: [a]\n",
    "* Medio: [e][o]\n",
    "* Cerrada: [i][u]\n",
    "**Localizacion (donde esta la parte mas alta de la lengua):**\n",
    "* Anterior [a][e][i]\n",
    "* Centro:\n",
    "* Posterior: [o][u]\n",
    "**Cuan redondeados estan los labios:**\n",
    "* Redondeados: [o][u]\n",
    "* No redondeados [a][e][i]\n",
    "\n",
    "### Secuencias de sonidos vocalicos:\n",
    "* Simple [e] vs diptongo [ei] vs triptongo [uei]. \n",
    "* Hiato: caer, zoologico, periodo, chiita. \n",
    "\n",
    "**Diferencia entre diptongo e hiato:**\n",
    "Hiato es la ruptura del diptongo. El diptongo es cuando tenes en la misma silaba dos vocales (abierta y cerrada me parece). Caer es un hiato por ejemplo.\n",
    "\n",
    "* **Consonantes:**\n",
    "\n",
    "### Taxonomias de las consonantes:\n",
    "* **Sonoras (porque vibran las cuerdas vocales):**  [m] [n] [b] [d] [l] [r] [g]\n",
    "* **Mudas (o sordas):** [f] [s] [p] [t] [k] [x] [integral] [h]\n",
    "\n",
    "* Punto de articulacion: el lugar donde se restringe el flujo del aire\n",
    "* Labial: bilabial [p] [m] [b]; labiodental [f] [v]\n",
    "* Dental: [tita] zorro en espaniol peninsular, la z cae aca\n",
    "* Alveolar: [s] [n] [t] [r] [m]\n",
    "* Palatal: niato (la n con la patita en la primera)\n",
    "* Velar: Hongo [segunda patita], [k] casa, [x] juez\n",
    "* Laringea: [h] hasta\n",
    "\n",
    "### Modo de articulacion:\n",
    "**Como se restringe el flujo del aire.**\n",
    "* Oclusiva: se bloquea el paso del aire y luego se lo libera [p] [t] [k] [g]\n",
    "* Nasal: el aire sale por la nariz [m] [n]\n",
    "* Fricativa: Se fuerza el aire por un canal angosto, generando una friccion turbulenta [f][s]\n",
    "* Africada: comienza como una oclusiva, pero termina como una fricativa [t integral]techo\n",
    "* Aproximante: se restringe poco el flujo del aire, sin bloquear ni producir friccion turbulenta [l]\n",
    "* Vibrante: se hace vibrar la lengua [r]\n",
    "\n",
    "La p y la m son parecidas una freno el flujo de aire y la otra no.\n",
    "\n",
    "La B va a tener diferentes formas de pronunciarla, diferentes fonos, bebe por ejemplo. Elijo diferentes sonidos para la misma categoria linguistica.\n",
    "\n",
    "Enfermo esa n es muy parecida a una m.\n",
    "\n",
    "## Fonos y fonemas:\n",
    "Sopa vs desde vs mosca vs “es uno”. Son diferentes formas de pronunciar la “s”. La forma en que se escriben es el espaniol, el lenguaje. Entre el lenguaje y la acustica hay dos niveles, fonetico y fonologico. A nivel fonetico la s tiene cuatro sonidos distintos aca. Todos corresponden a un unico fonema!.\n",
    "\n",
    "* **Fonos:** sonidos de un idioma, van entre []\n",
    "* **Fonemas:** clases de sonidos que permiten distinguir palabras de un idioma, van entre / /\n",
    "Dos fonos distintos en la misma clase son alofonos entre si.\n",
    "Ejemplos en espaniol:\n",
    "Desde, sopa, mosca: varios fonos [h] [s] [x] para /s/ \n",
    "Nada, enfermo: fonos [n] [m con patita] fonema /n/\n",
    "\n",
    "Los que son **alofonos** en espaniol, no lo son en ingles por ejemplo.\n",
    "La s, la h, la j, todas estas van a ser /s/. Instanciaciones de /s/. Yo puedo agarrar desde y decir la s como cualquiera de estos 4 fonos. Obvio va a sonar medio mal pero se puede. No cambia la palabra. Cambia el sonido nomas.\n",
    "\n",
    "La s ruido blanco en las frecuencias mas altas!\n",
    "\n",
    "## Formantes: \n",
    "Son picos de intensidad en el espectro de un sonido. Aparecen en un espectograma como bandas negras aproximadamente horizontales. La a tiene 4 formantes. Si ubico los formantes de vocales, puedo saber que vocal es.\n",
    "\n",
    "## Fenomenos foneticos importantes:\n",
    "\n",
    "* **Reduccion (o hipoarticulacion):** acortamiento de los sonidos, por ejemplo por hablar rapido.\n",
    "* **Eliminacion (consistente) de fonemas:** fosforo (foforo), septiembre (setiembre)\n",
    "* **Hiperarticulacion:** pronunciacion muy marcada (exagerada) de cada sonido. Como cuando no me entendiste algo y lo remarco al decirlo de nuevo.\n",
    "* **Co-articulacion:** coordinacion de movimientos articulatorios para la realizacion de un sonido\n",
    "Ejemplo: en pa, la lengua adopta la posicion articulatoria de [a] mientras se esta articulando [p]\n",
    "* **Asimilacion:** la pronunciacion de una silaba se acomoda a la de una vecina: hongo, desde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estructura del discurso:\n",
    "Misma oracion, misma semantica, pero diferentes intenciones, interrogar, afirmar, etc.\n",
    "\n",
    "Hay mucha mas informacion mas alla de las palabras. La prosodia. Es todo lo que diferencia al texto del habla. Hace frio puede ser una pregunta, o puede ser una afirmacion. Eso no esta en las palabras, la forma en que se dicen esas palabras esta en la prosodia. Si yo estoy corrigiendo a alguien que pronuncio algo mal voy a remarcarlo, Corea del NORte. Las partes que queremos marcar le damos un tipo de enfasis, como levantar la voz, etc.  Hay millones de factores, como por ejemplo nuestras intenciones, la estructura sintactica de lo que estamos diciendo, nuestra forma de ser, de donde somos, etc.\n",
    "\n",
    "Sabemos que a alto nivel reconocemos un susurro o una voz tensa o difonica. Eso esta relacionado con muchos atributos acusticos pero no hay un mapeo uno a uno como si hay en los otros casos.\n",
    "\n",
    "## Que es la prosodia?\n",
    "“Uso de caracteristicas suprasegmentales para comunicar significados pragmaticos al nivel de la oracion”\n",
    "\n",
    "* **Caracteristicas suprasegmentales:**\n",
    "En lugar de hablar de un fono o de una unidad o un segmento, son propiedades que abarcan a mas de un fono, mas de una unidad, mas de una palabra. Entonces vamos a estar hablando de caracteristicas como la F0 o la intensidad, no de un fono aislado sino de varias unidades. Ver la trayectoria de una de estas variables a lo largo del tiempo, durante varios segmentos, por encima de los segmentos.\n",
    "* **Comunicar significados pragmaticos al nivel de la oracion:**\n",
    "Son las intenciones del mensaje! (si le digo podes abrir la puerta no es de la habilidad que tiene de abrir la puerta sino que la intencion generalmente va a ser un pedido)\n",
    "\n",
    "### Dimensiones de la prosodia:\n",
    "\n",
    "* **Intensidad:**\n",
    "Es el volumen de la voz. Fuerte/suave. Amplitud, RMS -> Decibeles.\n",
    "* **Nivel tonal:**\n",
    "Aguda/grave. Frecuencia fundamental -> Hertz\n",
    "* **Tasa del habla:** \n",
    "Rapida/lenta. Cantidad de unidades por segundo, por minuto. Puede ser palabras por segundo, silabas por segundo, fonos por segundo, etc. Si tenemos el una transcripcion alineada (manual o automatica), el reconocedor del habla que agarra la senial y te tira las palabras, podemos calcular esto facil. Comunmente no hacer entero el reconocimiento del habla sino reconocer las silabas. Es algo que se reconoce mucho mas facil que todo el habla. Hay picos de intensidad en las silabas. En base a intensidad se puede sacar el piquito para cada una de las silavas.\n",
    "* **Calidad de la voz:** \n",
    "Susurro, voz tensa, voz rasposa, etc. Es bastante mas nuevo, tipo en los 90. A final de la decada pasada empezo a aparecer en los estudios de la prosodia. No se conoce todavia bien.\n",
    "\n",
    "### Variables acusticas relacionadas:\n",
    "* **mediciones de bajo nivel, acustico:**\n",
    "* Jitter, shimmer: perturbaciones en la periodicidad de la senial (frecuencia y amplitud, respectivamente). Jitter es cuanto se desvia de la onda senoidal pura respecto a las frecuencias. Supongamos que tenemos una onda de 100 hz senoidal simple pero que tiene una pequenia desviacion. Entonces de repente es un poco mas grande, de repente un poco mas chica y asi. Estas pequenias fluctuaciones  que va a haber ciclo a ciclo respecto de la onda pura. Eso lo mide el Jitter. El shimmer es lo mismo pero respecto a la amplitud. Si la amplitud de la onda media es esta y tenemos diferencias con la otra onda, mide eso. Esas perturbaciones con respecto a la media de un segmento.\n",
    "* **Relacion ruido-armonico (NHR y HNR):**\n",
    "Relacion entre componentes periodicas (armonicos) y no periodicas (ruido). Por ejemplo cuando mezclamos en praat, crear un sonido con una componente periodica y una que es gauss. Ahi mezclamos una periodica armonica y no armonica. Miden esa relacion el NHR y HNR.\n",
    "\n",
    "### Mediciones descriptivas:\n",
    "Correlatos perceptuales:\n",
    "Son cosas que sabemos describir perceptualmente. Sabemos describirlas segun la impresion que nos da.\n",
    "Voz clara, limpia vs rasposa, ronca, crujiente\n",
    "Voz relajada vs tensa\n",
    "Usada para estudiar patologias del habla\n",
    "Tiene su correlato en las intenciones! Si te lo dice susurrando puede ser un secreto!\n",
    "\n",
    "Que pasa si el chabon está disfónico por enfermedad? Me cambia los valores de HNR por ejemplo. Dentro de los parametros medios de un hablante, en un momento dado (hasta te cambia la voz despues de comer) las fluctuaciones dentro de ese momento, pueden darte informacion util para las intenciones.\n",
    "\n",
    "Aca vemos con cosas que podemos medir. Todo de bajo nivel. Intensidad, F0, etc. Me falta poder hacer algo con todo esto. A nivel espectral, ver que patrones aparecen, tenemos la facilidad que para reconocer habla tenemos bien representados los fonos. Y arriba los fonemas que los agrupan y arriba las silabas y palabras. El camino por ese lado esta bien marcado. Se trata de reconocer patrones en el espectro.\n",
    "\n",
    "Eso no lo tenemos aca. Aca no hay ninguna convención de como hacer una pregunta por ejemplo. Siempre nos enseniaron a pronunciar bien los fonos pero esto no. Nunca nos dijeron, la entonacion de una pregunta se hace asi. La musica tiene el pentagrama por ejemplo. Nos falta una buena teoria sobre la cual apoyarnos. Vamos a ver una teoria posible para representar la posible. Es un problema EXTREMADAMENTE ABIERTO. Hay MUY POCO CONSENSO. Nadie me dice, para aprender aleman, la prosodia es este dibujito. No te dicen como se hace una pregunta en aleman, una ironia.\n",
    "\n",
    "ToBI es una teoria posible para representar la prosodia. Hay muy poco concenso. La prosodia tambien te da el saber si la persona va a seguir hablando o va a parar (cedio la palabra).\n",
    "\n",
    "## Variacion prosodica:\n",
    "Como representar diferencias en:\n",
    "Intensidad, velocidad, prominencia, frases prosodicas, contorno entonacional, calidad del habla.\n",
    "Que aspectos del habla son relevantes? Son atributos continuos o categoricos? La entonacion es ascendente y punto? O la pendiente es tal subio tal numero real o que onda?\n",
    "\n",
    "En ese intento de modelar la prosodia, hacemos algunas observaciones que surgen del analisis de los datos. Tenemos dos grandes cosas que ocurren.\n",
    "\n",
    "La variacion prosodica abarca:\n",
    "Niveles de prominencia -> acentos tonales. El como de comer que esta mas marcado del como de cual que, es un ejemplo de nivel de prominencia distinto (esta mas marcado).\n",
    "\n",
    "Estructura de frases prosodicas. Lo que distingue no cantes victoria de no cantes, victoria es que hay una frase prosodica y en la otra dos., no cantes con coma o todo junto. \n",
    "\n",
    "Estos son los elementos de mas alto nivel posible que podemos detectar. Como se manifiestan estos eventos? Veamos que estamos haciendo algo categorico! \n",
    "\n",
    "Eventos prosodicos marcados por:\n",
    "Prolongaciones segmentales. El como el mo era mas corto que en el otro etc.\n",
    "Cambios en F0, intensidad y calidad de la voz\n",
    "Limites de frases -> muchas veces seguidos de pausas, pero no siempre. El silencio que delimita las frases tambien ayuda a entender la prosodia.\n",
    "\n",
    "### Para que modelar la prosodia?\n",
    "Sistema de sintesis del habla (TTS):\n",
    "Expresar sin ambiguedad el mensaje deseado:\n",
    "Ej: Maria no renuncio [,] por el sueldo. Lo tiene que decir de la manera correcta.\n",
    "Lograr mayor naturalidad\n",
    "Digresion: los robots deberian sonar humanos? A medida que crece la naturalidad se llega a un punto que genera rechazo. Esperamos cierta artificialidad. Quiza las siguientes generaciones no les pase esto.\n",
    "\n",
    "Ojo que estamos al nivel de generar audio. Tenemos tantos datos que quiza podamos falsificar la voz de Obama y hacer que diga algo que provoque un conflicto!\n",
    "\n",
    "## Sistema de reconocimiento del habla (ASR):\n",
    "Comprender el mensaje expresado por el hablante. Hay que reconocer bien las comas!\n",
    "Tareas mas especificas:\n",
    "Segmentar en temas\n",
    "Tener la estructura del discurso, meto un comentario, etc.\n",
    "Encontrar los puntos mas relevantes\n",
    "\n",
    "## Sistemas de dialogo hablado (SDH):\n",
    "Manejar bien los protocolos para ceder y tomar la palabra.\n",
    "\n",
    "Modelos de variacion tonal\n",
    "Dos tipos de modelos de variacion tonal:\n",
    "Modelo lineal o secuencia de tonos. \n",
    "Secuencia de eventos discretos de un lexico entonacional\n",
    "Modelo superposicional:\n",
    "Jerarquia de componentes fonologicas (es numerico)\n",
    "Modelo de secuencia de tonos:\n",
    "El mas conocido de secuencia de tonos es ToBI (es discreto, categorico. Tenemos una cantidad discreta de cosas que podemos identificar. Vamos a tener un lexico entonacional). Tiene dos objetivos tonales, los acentos tonales (como acentuamos una palabra. VOY SIEMPRE tiene acento tonal, y VOY SIEMPRE Y CUANDO…) y los tonos de final de frase (los que me diferencian el no cantes victoria de no cantes, victoria).\n",
    "\n",
    "## Unidad basica de descripcion:\n",
    "Frase entonacional (L-, H-). Cuando agarramos un texto, tenemos la oracion, con sujeto predicado, etc. Empiezo de una entidad grande partiendola de a cachos. Aca tambien hay una gramatica en ToBI donde la unidad es la frase entonacional. No necesariamente coincide con una oracion. A veces esta delimitada por pausas o por acento de final de frase.\n",
    "\n",
    "Delimitada por pausas y/o por una prolongacion en el final de la frase (acento de final de frase)\n",
    "Cada silaba puede tener acento lexico y/o acento tonal.\n",
    "\n",
    "Todas las palabras tienen acento lexico (lo que nos enseniaron de aguda grave esdrujula) pero no necesariamente se manifiesta como un acento tonal. La mayoria de lo que decimos no tienen tonal, articulos, etc. Las que unen a los verbos, sustantivos, adjetivos. Cuando lo decis dentro de una oracion no lo acentuas por ejemplo. Cuando uno lo dice en una oracion no lo acentua con un acento tonal. VOY SIEMPRE tiene acento tonal, y VOY SIEMPRE Y CUANDO… no tiene acento tonal!\n",
    "\n",
    "Los acentos tonales se marcan mediante uno o mas de estos:\n",
    "{pico de F0, pico de intensidad, prolongacion de la silaba}\n",
    "\n",
    "## Sistema ToBI:\n",
    "Objetivos:\n",
    "Armar un sistema de anotacion para la prosodia del ingles NA que fuese robusto y confiable\n",
    "Promover la disponibilidad de cuerpos de datos anotados prosodicamente siguiendo un estandar, que pudieran ser compartidos por la comunidad.\n",
    "\n",
    "Una transcripcion de ToBI requiere:\n",
    "Grabacion de habla\n",
    "Contorno de F0 (pitch track)\n",
    "4 capas (tiers) de ToBI:\n",
    "Capa ortografica: palabras\n",
    "Capa de junturas entre palabras (break-index tier). Va de 0 - 4 . El 0 es cuando dos palabras se pegan como la argentina. Se pega. Largentina. El 1 es el tipico entre dos palabras cualesquiera. 3 y 4 son finales de frase.\n",
    "Capa tonal: acentos tonales, tonos de final de frase\n",
    "Capa miscelanea: disfluencias, toses, risas, etc\n",
    "\n",
    "TOBI ES UNA CAPA INTERMEDIA DE REPRESENTACIÓN DE LA PROSODIA. ASI COMO EN LA ACUSTICA USAMOS LA FONETICA. PARA LA PROSODIA USAMOS TOBI. TRATA DE ABSTRAER VARIANTES EN UNA SOLA ETIQUETA. ESTA ETIQUETA SE USA PARA CONTRASTE? PARA IRONIA?\n",
    "\n",
    "Cuando uno diseña un sistema de etiquetado, uno quiere etiquetar todas las preguntas por ejemplo. Es muy bueno que haya consenso. Que todos los que lo usen, etiqueten lo mismo! La gente se tiene que poner de acuerdo de como usarlo!\n",
    "\n",
    "## Modelo superposicional de Fujisaki:\n",
    "Es totalmente numerico. Es usado principalmente para sintesis y algunos estudios mas teoricos de la prosodia. ToBI es para todo.\n",
    "\n",
    "La idea es, uno tiene una oracion declarativa, uno cuando va hablando va perdiendo aire. Trato de modelarla con una regresion (esa perdida de aire). Las riquezas locales que tiene la oracion las modelo con los gorritos (hay que detectar cuántos picos hay! Funciona bien automaticamente). Se ajusta un modelo y listo. La suma de las dos cosas es lo del =. Es una buena aproximación al contorno entonacional de la frase.\n",
    "\n",
    "Se usa en las grabaciones que usa para sistemas de sintesis. Cuando entra una oracion nueva, trata de estimar esto, construye los modelitos y ve la forma que tendria que tener la F0 en la senial.\n",
    "Usado principalmente para sintesis del habla.\n",
    "\n",
    "Modela el patron de F0 con una superposicion lineal de dos componentes: de frase y de acentos.\n",
    "\n",
    "La frase tiene una forma basica (ej: descendente)\n",
    "\n",
    "Cada acento tiene su propia forma parametrizable\n",
    "\n",
    "**Desventajas:**\n",
    "No modela los diferentes tipos de acentos, ni las variaciones en finales de frase\n",
    "Muy especifico para sintesis; no adecuado para estudiar la variacion prosodica en general\n",
    "\n",
    "## Modificacion de la prosodia\n",
    "Tenemos una oracion puede ser que ya este sintetizada o esta grabada y le quiero cambiar la prosodia.\n",
    "\n",
    "En sintesis concatenativa, todas las unidades tienen las mismas variables prosodicas (F0, int, dur). Estan grabadas, no puedo hacer nada. SI queria decir Hola mundo como pregunta, y no tengo las unidades, entonces sone. Las puedo modificar con proc de seniales.\n",
    "\n",
    "La prosodia deseada se consigue con proc de seniales.\n",
    "\n",
    "La intensidad se puede modificar facilmente\n",
    "\n",
    "* **Como modificar tono y duracion?**\n",
    "\n",
    "Aumentar la duracion de una senial disminuye el tono.\n",
    "\n",
    "### TD-PSOLA:\n",
    "Por un lado identifica los ciclos basicos de la senial. Si queremos cambiar la duracion los duplicamos o borramos. Para cambiar el tono los juntamos o los separamos. Para identificar ciclos podemos usar autocorrelacion.\n",
    "\n",
    "Con esto lo tengo perfectamente separados los ciclos basicos (EGG).\n",
    "\n",
    "Tenemos que juntar o separar la cantidad de ciclos para que el patron espectral aparezca mas veces por segundo. A tono fuerte y A tono bajo, es el mismo patron pero aparece mas veces. Para simular esto, ahi tenemos 5 ciclos y a cada uno le aplico un filtro, ventana de hanning, que lo que hace es al ciclo, achicarlo de ambos lados. Al recortar y pegar se suman. Fijate que agarra como una gaussiana y alisa las puntas! Con frecuencais bajas anda bastante bien, con altas rompes todo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sintesis articulatoria:\n",
    "Es esencialmente, todo lo que conocemos del tracto vocal, simularlo en una computadora. Usan tubos simulados por computadora con diferentes largos y anchos y simulan las ondas que pasan. Van acomodando estas cosas para tratar de simular el tracto vocal.\n",
    "\n",
    "## Sintesis de formantes:\n",
    "Lo que trata de hacer es generar la onda de salida, no trata de simular el tracto vocal, simplemente ir a generar, dibujar la onda que tiene que dibujarse, para que al escucharse nos demos cuenta. Todo esto con una caja negra. A una fuente de sonido le aplica una combinacion de filtros y trata de generar la onda del fono.\n",
    "Sintesis basada en HMM:\n",
    "HMM ES GENERATIVO. Entrenan un sistema de reconocimiento, se entrena eso (es generativo) y te tira la sintesis. Que sea generativo es que podes darlo vuelta y producir habla nueva. Tengo habla reconozco una secuencia de fonemas, puedo agarrar una secuencia de fonemas y dar una senial de habla.\n",
    "Sintesis concatenativa:\n",
    "Es esencialmente cortar y pegar. La hora oficial del 113 por ejemplo. Las unidades son palabras enteras por ejemplo. Se lleva al extremo usando difonos. Para todos los pares posibles de sonidos de un lenguaje va desde la parte estable de un sonido hasta la parte estable del siguiente. A esto se le llama difono, es la unidad fundamental de la sintesis concatenativa. Esto se grava, se recorta y despues se pegan. Podemos tener 200 sa. Despues tenemos que elegir cual usar, por ejemplo camino minimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTS:\n",
    "Hasta ahora los temas fueron principalmente dentro del problema de generar habla artificial, los temas que no vimos fueron los de sintesis propiamente dicha del habla. A partir de una secuencia de fonemas llegar a audio, a habla. La otra mitad seria como llegar de una oracion, texto, a esa representacion en fonemas. Es bastante facil no? Dado un texto llegar fonemas?\n",
    "\n",
    "River plate. PLEIT es en ingles! Madafaka!. Salio 3-1, 3 guion uno? 3 a uno? 3 menos 1? Porque sabemos que hablamos de futbol! La calle monroe, marilyn monroe.\n",
    "\n",
    "La clase pasada tomamos como punto de partida el conjunto de fonemas con una notacion de prosodia. En el tp eran los tildes y los signos de pregunta.\n",
    "\n",
    "Punto de partida es la secuencia de fonemas y quiero audio. Esto es el back end.\n",
    "\n",
    "En el medio teniamos cualquier tipo de sintesis propiamente dicha, como concatenativa (la del tp con concatenacion de difonos), la articulatoria que modela el tracto vocal, formantes era armar directamente la onda. Todo esto lo damos por sabido y nos vamos a enfocar en la clase de hoy. Partimos de cualquier texto en algun formato, una web, un tweet, etc.\n",
    "\n",
    "Vamos a pasar por toda una secuencia de cosas para llegar a una secuencia de fonemas con una prosodia deseada.\n",
    "Los pasos son:\n",
    "\n",
    "Primero procesar el texto de entrada, entender que es una palabra, que es una oracion, normalizar el texto.\n",
    "Depsues vamos a hacer un analisis linguistico. Eso lo vamos a ver en orden inverso aca lo vamos a ver primero la parte fonetica y vamos a ver porque sirve la parte linguistoica. Y como ultimo el analisis prosodico que es asignar una prosodia a cada fonema.\n",
    "\n",
    "## Procesamiento del texto de entrada:\n",
    "Tenemos que empezar a pensar el problema desde la raiz. Que es una palabra? Cual es la unidad minima para comunicar significado? EE UU es un token pero hay que llevarlo a dos, Estados unidos.\n",
    "\n",
    "## Tokenizacion:\n",
    "Hay que elegir un delimitador. Por ejemplo el espacio. Podemos elegir los puntos, el guion es un fin de palabra? El apostrofe? Puedo tener una tablita de excepciones para las que tienen guiones o apostrofes. Despues no hay mayores problemas para partir esto en unidades. Esto en chino, japones, coreano, no es para nada trivial. Usan ideogramas! Se pueden agrupar de distintas maneras y significan distintas cosas!\n",
    "En otros idiomas elegir el token no es trivial! En la mayoría de los idiomas occidentales no es un problema.\n",
    "Ahora el siguiente problema, es detectar una oración. Al sintetizador le paso una oración entera y que la procese. Usar el punto tiene algunos problemas 2.500 falla! O Higgins pdte. Tambien.\n",
    "Los simbolos que tambien pueden significar comienzo y fin de oracion son los ! ? Puede ser que despues de un signo de pregunta siga la oracion!\n",
    "\n",
    "Como resolvemos esto?\n",
    "\n",
    "Abreviaturas, hay que extender las abreviaturas. Podriamos tener una tablita! Todo esto cambia todo el tiempo!\n",
    "Por ejemplo un mensaje xfa sbdo dnd kdms?\n",
    "Emoticones!\n",
    "\n",
    "Si el mensaje es de una mala noticia pero tiene un emoticon, puede cambiar! Como, che estas despedido y te pone el emoticon de homero. GG BRO.\n",
    "\n",
    "Si queremos hacerle una joda a un amigo si emoticones hay que armar bien la oracion para que no lo tome a mal.\n",
    "Tenemos que procesar las abreviaturas, y las tablas a veces son imposibles de hacer! En texto mas convencional sirven pero despues en la parte mas creativa no hay nada que hacer, aparecen decenas por dia de abreviaturas. Hay que tener ideas un poco mas creativas.\n",
    "\n",
    "Tres clases de abreviaturas.\n",
    "* **Abreviatura:**\n",
    "Secuencia de letras usadas para representar de forma breve una palabra o una frase: cap., pag., Cia., km, srta.\n",
    "* **Sigla:**\n",
    "Palabra formada por las letras iniciales de una expresion compuesta: ONU, IVA, DGI, IBM, AFIP.\n",
    "\n",
    "* **Acronimo:**\n",
    "Palabra formada por las letras iniciales de una expresion compuesta pero que suele ajustarse a las reglas fonologicas de la lengua.\n",
    "Originalmente eran siglas y se transformaron en palabras. Sida, Radar, Ovni, Laser.\n",
    "\n",
    "Si tenemos abreviaturas conocidas podemos usar tablas. Cuidado con el número! 1kg vs 5kg, un kilogramo y 5 kilogramos! La s final.\n",
    "\n",
    "5m son 5 minutos o 5 metros? Necesito saber el dominio/tópico del contexto!\n",
    "\n",
    "Si es del futbol pueden ser las dos cosas!\n",
    "\n",
    "Una idea linda para el problema de las abreviaturas. Parto de la palabra completa y genero posibles abreviaturas. Si una persona quiere decir terraza, cuales son las posibles formas de abreviarlo que se le pueden ocurrir a un humano? Trz, terr, algo de la palabra original va a conservar! \n",
    "\n",
    "Usamos maquinas de estado finitos!\n",
    "\n",
    "Esto se puede generalizar! Cuando tengamos todas las formas de producir numeros esto es un monstruo gigantesco. A esto le agregamos todas las abreviaturas que conocemos. Cada vez que agregamos algo hay que recompilarlo. Y al mismo tiempo vamos a ir metiendo datos para que esto. A todo lo que no sea dato para expandir va a ir pasando. Lee boca, despues Jrs. Va a haber una posibilidad un peso. Cada transicion va a tener un peso. Una posibilidad va a ser Jrs con algun peso, algun premio chiquitito, va a haber otro camino, jrs asociada a junior que me permita expandir esto a junior que va a tener un premio mejor! Dado que ese camino sea preferible. Entonces el camino que me expanda esto a junior va a ser elegido a la hora de usar el automata este. Aplicar esto me va a dar un automata mas con un monton de posibilidades, todas las formas posibles de procesar este texto. Ahora tengo que encontrar el camino óptimo! Puede que siga habiendo caminos muy parecidos, tendriamos que usar informacion por fuera del dominio para ayudarlo. Como hacer eso? Otro gran problema. Se hace todo en un mismo proceso, transformar numeros abreviaturas y finalizacion de oraciones.\n",
    "\n",
    "Necesitamos mas informacion. Necesitamos saber de la sintaxis a veces para desambiguar. Vamos a tener una solución generica, vamos a podar los caminos mas improbables y nos vamos a quedar con una codificacion de todas las formas de expandir esa oracion. Esto es lo que vamos a usar mas adelante. Esta la forma de expandirlo como fin de oracion o como nada.\n",
    "\n",
    "Voy componiendo automatas, el de numeros con abreviaturas, etc.\n",
    "Uno agarra un texto, lo transforma en una secuencia, lo compone con este automata y genera un automata resultado, lo corre varias veces para podar las ramas inservibles y despues de esa poda queda ambiguo, un automata con todas las formas de expandir las oraciones que uno tiene.\n",
    "\n",
    "Problemas:\n",
    "Tokenizacion (identificar palabras)\n",
    "Segmentacion (identificar oraciones)\n",
    "Expansion de abreviaturas\n",
    "Expansion de expresiones numéricas\n",
    "Todo esto se soluciona dentro del mismo framework (automatas). En el medio hay muchas decisiones, cómo se construyen las tablas por ejemplo. Como construimos el autómata? Para una empresa chica, por ejemplo el vocabulario de un GPS podemos hacer cosas a mano, tablas!\n",
    "\n",
    "Soluciones:\n",
    "Reglas hechas a mano, tablas, etc\n",
    "Desarrollo rápido y sencillo, buenos resultados\n",
    "Atado al dominio, mantenimiento lento\n",
    "Enfoques de ML\n",
    "Mejores resultados, independiente del dominio, mantenimiento rápido\n",
    "Desarrollo más costoso y sofisticado (pero no tanto!)\n",
    "Principal obstaculo: DATOS\n",
    "\n",
    "## Analisis fonetico: grafemas -> fonemas.\n",
    "Hasta ahora no tome ninguna decision fonetica. River plate sigue siendo River Plate. Quiero pasar de grafemas a fonemas, de letras a fonemas.\n",
    "\n",
    "Que codifica el lenguaje escrito?\n",
    "Para un front end necesitamos una funcion que:\n",
    "Texto arbitrario -> secuencia de fonemas con prosodia\n",
    "Uno puede pensar que tiene una tablita de texto a fonemas. Pero hay problemas.\n",
    "Codifica el lenguaje escrito un mensaje oral?\n",
    "Existe F: alfabeto -> habla\n",
    "Provee el lenguaje escrito toda la informacion necesaria para reconstruir el mensaje oral?\n",
    "Si no, cómo hacemos para leer un texto en voz alta?\n",
    "Que codifica el lenguaje escrito?\n",
    "Alfabeto -> pronunciación? significado?\n",
    "SI estas funciones existieran, las implementamos. Ahora, si no existe, la transición de los símbolos que escribimos en un papel a habla necesita datos de otro lado. Hay cosas que están faltando, esos argumentos puede ser la cultura, conocimiento del mundo, etc. Hay que saber de futbol para leer boca salio 3-1 por ejemplo.\n",
    "\n",
    "Puede que ni siquiera sea una funcion, que sea una relacion.\n",
    "De todas las formas de decir las cosas, nuestro sistema tiene que elegir una. Si no hay una función, que es lo que codifica el alfabeto? La pronunciación, el significado? Las letras tienen significado propio? Kiki buba, algo de significado tienen! En chino tenemos pronunciacion y algo de significado.\n",
    "\n",
    "Alfabetos del griego codifican solo pronunciacion!.\n",
    "En ingles se va todo a la mierda, blood vs broom, though vs cough. La escritura vs pronunciacion al carajo se va.\n",
    "\n",
    "En espaniol casi que alcanza con crear reglas de esta forma:\n",
    "\n",
    "Cada vez que encuentres una C, si esta seguida de a o u, entonces a la C reemplazala por el fonema /k/. Y asi sucesivamente.\n",
    "La cantidad de excepciones en ingles es un despelote!\n",
    "Otro enfoque es basados en diccionarios. Agarro todas las palabras de ingles que pueda conseguir y le pago a un fonetista. Esto esta hecho en muchos diccionarios.\n",
    "Supongamos que esto funciona por ahora. Va a pasar que por mas bueno que sea mi diccionario, van a haber monton de palabras que no estan. Como Mike Moore, Sanchez, O Higgins, etc.\n",
    "Hay que hacer algo mas con esto.\n",
    "Esto es un problema grande! Hay un paper del 98 de Alan Black.\n",
    "Problema: palabras fuera de vocabulario (OOV)\n",
    "Un paper de el dice que tenian un corpus de 40k de palabras, se fijaron con uno de los diccionarios y el 4.4% no estaba. 1360 eran nombres propios, 351 eran palabras desconocidas (nuevas, extranjeras) 64 eran typos.\n",
    "\n",
    "Como solucionar esto?\n",
    "Agrandar el diccionario (mala decision), no alcanza solo con esto, no nos va a ir bien.\n",
    "Dado que sabemos que el dicc esta incompleto, arreglamos estas reglas:\n",
    "Usar reglas letra-a-sonido cuando no se encuentre una palabra en el diccionario\n",
    "Palabras extranjeras\n",
    "Inferir el idioma de origen, usar reglas del idioma (si estan disponibles)\n",
    "Jackson, tchebicheff, ahmadinajad, ininiti\n",
    "Reglas de reescritura. (Fakrell and skut 2004) identifica alteraciones de escritura que sean neutrales con respecto a pronunciacion y luego trata de reescribir esas palabras para ver si caen en algo conocido. Tenemos britney pero Brittany no, tenemos reglas que la y se puede transformar en una i, la oo en una simple o. Son posibles formas de reescritura. Es un mapeo difuso.\n",
    "\n",
    "Britney/Brittany son homofonos.\n",
    "\n",
    "Buscar un mapeo difuso entre palabras OOV y palabras que si figuran en el lexico\n",
    "Identificar alteraciones de escritura que sean neutrales respecto a la pronunciacion, para asi producir reglas de escritura para palabras OOV.\n",
    "\n",
    "La distribucion de typos esta bastante estudiado, uno le pifia normalmente a una vecindad de las teclas cerca del teclado, una s por una d por ejemplo. Tenes en la d una probabilidad mayor de que haya sido una s por ejemplo.\n",
    "Paper del 2009, derivar pronunciaciones de la web. Buscar en la web, muchas veces en los diarios ponen como se pronuncian ciertas cosas.\n",
    "Bruschetta (pronounced broo-SKET-uh)\n",
    "Con esto tuvieron muy buenos resultados.\n",
    "Hay que validar candidatos porque se usa mucho pronounced dead, que llegaron a algun lugar y lo declararon muerto en el acto: Cuan probable es que estos pares representen una palabra y su correspondiente pronunciacion.\n",
    "\n",
    "Otra forma de tratar palabras fuera del vocabulario es hacer un analisis morfologico.\n",
    "Analisis morfologico, estudia la estructura de la formacion de las palabras.\n",
    "Sol tiene un solo morfema, sol\n",
    "Gatas tiene tres morfemas, gat- a - s (especie, genero y numero)\n",
    "Dos clases de morfemas: raices y afijos\n",
    "Raiz es la parte principal de la palabra (sol, gat-)\n",
    "Afijos: agregan significados adicionales (-a: femenino, -s: plural)\n",
    "Prefijos, sufijos, infijos/interfijos, circunfijos\n",
    "Pueden servir para inferir la pronunciacion de palabras OOV:\n",
    "Si tenemos reglas para desarmar una palabra en morfemas, listo!\n",
    "Ingles: demagnetizability -> de + magnet + ize + able + ity (ingles)\n",
    "espaniol: subregion -> sub-region (y no su bre gion) No tiene en cuenta la morfologia.\n",
    "\n",
    "Hay que darse cuenta que solo es un prefijo.\n",
    "\n",
    "No nos agregan un significado. Solamente facilitan la pronunciación (creo que los interfijos).\n",
    "\n",
    "Cómo combinar morfemas para crear palabras?\n",
    "\n",
    "En ingles hay palabras que aisladas no tienen una pronunciacion, tienen diferentes formas, lead, live, deser, bass. Bass o beiss.\n",
    "\n",
    "En espaniol, “como aca” como como adverbio o conjuntion.\n",
    "\n",
    "Lo que vamos a necesitar para desambiguar, es saber la clase de la palabra. Si es un verbo, sustantivo, etc. Si podemos inferir eso de la oración, del contexto, ya solucionamos BANDA de problemas.\n",
    "\n",
    "No siempre ayuda! bass/bass son los dos sustantivos! Lpm!\n",
    "Vamos a tener que apelar a informacion mas compleja.\n",
    "Analisis linguistico: ver que clase es cada palabra, hacer un parsing sintactico. Son cosas que nos van a acercar a una respuesta correcta (podemos aun asi pifiarle).\n",
    "\n",
    "(Part-of-speech, POS)\n",
    "Hay palabras que exhiben comportamiento parecido:\n",
    "Aparecen en contextos similares\n",
    "Desempeñan funciones similares en la oración\n",
    "Sufren transformaciones similares\n",
    "\n",
    "POS tagset:\n",
    "\n",
    "El Penn Treebank tagset esta muy orientado al ingles. Tenes un tag, una descripcion y ejemplos.\n",
    "\n",
    "Los algoritmos para hacer POS son bastante variados. La tarea es asignar una etiqueta de clase  palabra a cada cuadrado de un texto. Puede ser deterministico a una unica solucion o puede quedar abierto y elegir la mas probable.\n",
    "\n",
    "Pueden ser las moscas del tiempo, les puede gustar una flecha, dafuq bro.\n",
    "De ninguna manera esto es sencillo.\n",
    "\n",
    "## Rule-Based POS tagging:\n",
    "Primero lo que debemos hacer es asignar a cada palabra todos sus tags posibles. Toda palabra tiene un conjunto de tags. Despues tenemos un conjunto de reglas que hacemos nosotros para eliminar tags. Esto iteramos hasta que cada palabra tenga un solo tag. Por ejemplo las reglas pueden ser por cosas estadisticas de las palabras. Como se elije cuales usar en cada iteración? Eso es lo que hace variar de algoritmo en algoritmo. Esto es una familia de algoritmos.\n",
    "\n",
    "No nos metemos con el significado! Solo sacamos el tipo de palabra.\n",
    "\n",
    "Variantes del siguiente algoritmo:\n",
    "\n",
    "Asignar a cada palabra todos sus tags posibles\n",
    "\n",
    "Usar un conjunto de reglas predefinidas para eliminar tags selectivamente\n",
    "\n",
    "Iterar hasta que cada palabra tenga exactamente un tag\n",
    "\n",
    "Esta es una idea simple. Fue atacada por diferentes algoritmos hasta que llego machine learning y rompio todo.\n",
    "Hoy en dia la performance esta en 95-99%.\n",
    "\n",
    "Problema aparentemente resuelto? NO! Cuando no está limpio o no se parece mucho al texto de entrenamiento. Muy atado al dominio de los textos de entrenamiento. Habla espontánea, problema abierto.\n",
    "\n",
    "Son muy poco robustas al cambio de dominio.\n",
    "Una persona que está hablando, se equivoca, comete errores, tiene que volver para atrás, con toda la suerte del mundo podemos tener\n",
    "\n",
    "El este el libro tiene un tiene una foto en la t- no en la contratapa.\n",
    "No hay puntos, no hay nada de sintaxis marcada. Sobre esto, el problema esta totalmente abierto. Cuando tenes algo no bien formado se va todo al tacho.\n",
    "\n",
    "Hay una discusión grande ahora, un par de paper de opinión discutiendo sobre cuales son las perspectivas de deep learning en lenguaje natural. Si hay un motivo para usarlo, si tiene sentido, etc.\n",
    "\n",
    "El POS tagging nos puede dar para desambiguar en partes la interpretación. Como pronunciar. Supongamos que esto está resuelto, a partir de una frase llegar a las palabras correspondientes. A un etiquetado correcto.\n",
    "\n",
    "## Analisis sintactico:\n",
    "Se parte de una gramatica. Son ENORMES! La RAE saco una gramatica del espaniol y es GIGANTE! Esa gramatica se hace a mano por ejemplo. Una vez que la tenemos, podemos hacer parsing. Puede ser bottom up o top down.\n",
    "\n",
    "## Parsing estadistico:\n",
    "Decidir que regla usar en base a estadisticas tomadas de cuerpos de datos\n",
    "Cada regla tiene un aprobabilidad en el estadistico\n",
    "\n",
    "## Parsing de dependencias:\n",
    "Grafo: nodo=palabras, aristas=dependencias\n",
    "Construido en base a estadísticas tomadas de cuerpos de datos\n",
    "Ventaja: no hay que definir una gramática\n",
    "\n",
    "Esto lo podemos usar para desambiguar el hecho de si termina la oracion o no. El parsing va a arrojar cierta probabilidad de que esto sea una oracion.\n",
    "Podemos usar el parsing para desambiguar si termina una oracion o no. Podemos usar las clases de palabra para desambiguar los fonemas led o liv.\n",
    "\n",
    "## Análisis prosódico: \n",
    "Asignación de prosodia (F0, dur, int)\n",
    "\n",
    "Vamos a querer que suene lo menos robotico posible. Tenemos que saber donde poner las pausas, si hay silencios o no. \n",
    "Las reglas manuales terminan en reemplazar coma con pausa. Son demasiadas. Es demasiado complejo el problema de la prosodia para encararlo asi. En un dominio muy chiquito tipo GPS puede andar. Sino tenemos que caer en machine learning.\n",
    "\n",
    "Nos parece que hay varias soluciones posibles. Es una tarea difusa. Pero no porque sea dificil, no hay que hacer nada al respecto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDH:\n",
    "Tener una maquina que dialogue con seres humanos. Falta la parte de que puedan entender. Los IVR son los de presione el boton 1 y eso, o decir comandos. Agentes conversacionales son los chatbox.\n",
    "\n",
    "Estaria bueno el reemplazar el, si se quiere comunicar con rr hh presione 1, y que directamente vos digas que queres hacer y te sepa rutear.\n",
    "\n",
    "Cuando el acceso a la pantalla, datos, mouse es limitado, ahi vale la pena usar un SDH.\n",
    "Arquitectura:\n",
    "\n",
    "Tenemos a nuestro usuario, y al sistema. Son componentes que arman un pipeline, es conceptual, no es real. Existía en los primeros sistemas, hoy en dia esta todo bastante interconectado. La persona habla, genera un habla y entra en el sistema de reconocimiento. Reconocimiento lo vemos a partir de la clase que viene. Nos alcanza con saber que como input nos da un audio y como output un conjunto de palabras. Es muy parecido a síntesis pero dado vuelta. El modulo de reconocimiento escupe un texto que tiene que ser entendido para el modulo de Language Understanding. Ahi entra texto, y sale en algun formato de base de datos o de logica o de alguna manera. Ahi se comprende el mensaje de lo que dijo el usuario. Esto viene a un modulo de administración de diálogo que va a tomar todas las decisiones del dominio, hacer una consulta a la BD, una transacción, lo que sea. Y va a escupir algo en un formato que estamos acostumbrados, que va a ser transformado a lenguaje natural. Arma las oraciones.\n",
    "\n",
    "Esto es tipo espejito de lo de arriba. Todo puede ser desde trivial hasta imposible. Y despues sintetiza, entra texto y sale audio. El tipito escucha audio y vuelve a empezar.\n",
    "\n",
    "Tipicamente un sistema de dialogo trabaja con muchisima incertidumbre. Es muy dificil en este contexto hacer un sistema de reconocimiento. Es el principal motivo por lo que hicieron lo de que la gente llama con mucho ruido desde el celular, esta en la calle, el celular mismo tiene interferencia, esta lleno de problemas. Va a ser muy ruidoso el archivo de audio. Ese es el contexto mas dificil de todos.\n",
    "\n",
    "### ASR para SDH es dificil:\n",
    "Disfluencias son cuando te equivocas y la arreglas tipo eeeee.\n",
    "ASR introduce inceritudmbre (me da probabilidades):\n",
    "\n",
    "El punto de partida en este mapa ya es una porqueria, una cosa ruidosa. Esa secuencia de palabras puede o no estar correcta! Podemos acotar el dominio lo mas que podamos para que esa incertidumbre quede acotada. El dominio de peliculas de cine por ejemplo.\n",
    "\n",
    "Language undersanding (comprensino del lenguaje natural):\n",
    "Queremos entender el lenguaje natural. Son formas de representar el significado de las oraciones (logicas de predicados, logicas modales, etc). Las de predicados suelen ser muy pesadas y se va a modales que son menos pesadas, en tiempos polinomial.\n",
    "\n",
    "Sistemas de dialogo hablado (dialog acts, frame/slot semantics)\n",
    "A la gente cuando llama que hable solo de transporte y demosle ejemplos de oraciones para que las entendamos. Que solo nos digan de donde quieren ir a donde quieren ir. \n",
    "\n",
    "Dialog acts, el del libro, jurafsky. Es una idea bastante simple, los actos de dialogo son algo que captura la accion que se pretende realizar, reformular una oracion en un dialogo. Cada vez que habla uno tiene una intencion. Son bastante pocas, son decenas. Cuanto más acotado esta el dominio, menos son. Una pregunta por si o por no, una solicitud, un agradecimiento, etc. Es complejo el tema pero es bastante mas simple. Es una forma de modelar las intensiones del lenguaje y empezar a bajando a la tierra (hacerlo procesable). Por ejemplo solo doy info del sistema de viajes de trenes. Funciona bastante bien en dominios acotados. Clasificar automaticamente en bases a oraciones. El usuario dijo esto. Voy a tratar de clasificar automaticamente.\n",
    "\n",
    "Tenes un monton de grabaciones de dialogos recolectados y en esos dialogos pones a gente etiquetar. Estos son de la parte diurna del dia cuando estaban los seres humanos haciendo la tarea esta.Hay muchas grabaciones con el mismo dominio y la misma estructura de la cual podemos aprender!  Se le pagaba a la gente para que etiquete. Que la clasifique, esto es una pregunta por si o por no, esto es un saludo, etc.\n",
    "\n",
    "Este es uno de los analisis que podemos hacer. Si sabemos que es una pregunta, el modulo que maneja el dialogo va a tener que dar una respuesta. Si es una respuesta, vamos a tener que tomar una decision. El modulo que maneje el dialogo va a necesitar esto. Pero no solo esto, es una de las cosas que nos conviene tener. Lo otro que vamos a querer saber es que cuando hay una afirmación vamos a querer llenar una fichita de este estilo\n",
    "\n",
    "Las gramáticas semánticas, son gramáticas que generan en los objetos terminales símbolos que tienen en común cosas sintácticas, características sintácticas, por ejemplo generamos sustantivos, o adjetivos, o tokens que tienen la misma característica, son todos literales, etc. Acá lo que generamos son frases que tienen la misma semántica (el mismo significado).\n",
    "\n",
    "Es un parsing comun y corriente. Como esta muy atado a nuestro dominio, seguro un parser deterministico anda barbaro.\n",
    "\n",
    "Es una estructura, una tecnica probabilistica de machine learning para detectar secuencias. Clasificacion se secuencias de etiquetas. Tengo una secuencia de cosas y quiero ponerle la secuencia mas probable de etiquetas. Tenemos estados ocultos, es un modelo de markov porque tenemos historia 1 sabemos de donde venimos y a donde vamos. Cada uno de estos estados ocultos pueden emitir observaciones. Esta emision a esas palabras es lo mismo de las semanticas. Esta forma de show te da diferentes estados terminales, simbolos terminales, aca te da lo mismo. SHOW puede emitir Show me. Esto es el resultado de correr el algoritmo, pero tenemos un grafo enorme lleno de nodos y necesitamos encontrar el camino que genere esta secuencia de etiquetas. Encontrar la explicacion mas probable para esta secuencia. Cual fue el recorrido que hizo el recorrido del cerebro del chabon para generar estas observaciones.\n",
    "\n",
    "A veces hay mala onda y lo dice en manera retorcida para generarle al otro un malestar. Si es una base que quieren cooperar esto vale. Esa máximas no se pueden demostrar.\n",
    "\n",
    "TODO ESTO ES PARA DOMINIOS LIMITADOS!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "## Manejo de dialogo (administrador del diálogo):\n",
    "Con elize nosotros vamos llevando la conversación. Con FSA, lo llevamos nosotros por el camino.\n",
    "\n",
    "Si cambia de opinion en el medio, hay flechas de vuelta. La experiencia de usuario es pobre porque es poco natural, sentis que estas llenando un form.\n",
    "\n",
    "A mayor flexibilidad mayor incertidumbre! \n",
    "\n",
    "Se la metes por piggy backing. Si era cordoba va a decir a Salta, si no era Cordoba va a decir, no dije Cordoba!.\n",
    "\n",
    "## Generación del lenguaje:\n",
    "\n",
    "Es bastante aburrido porque suele ser suficiente tener templates. Restricciones de HCI.\n",
    "\n",
    "Esto se debe a que todo esto anda en sistemas distribuidos! Quizá por esto cambiamos el dia! Tomamos malas decisiones sobre una oración mal formada. Debería ser, en este momento encontre 3 vuelos!\n",
    "\n",
    "## Speech Synthesis:\n",
    "\n",
    "Cuando aparecen nombres propios podemos usar difonos, HMMs, etc.\n",
    "\n",
    "Este esquema es falso, no es de a turnos. A veces hablo, hago un silencio, sigo hablando, agrego elementos en formas desordenadas. Esa pausa va a haber generado que esto deje de andar! Ademas el output de una cajita puede ser input de varias cajitas, como la prosodia que detecto cierta cajita.\n",
    "\n",
    "## Aplicaciones:\n",
    "Partimos de habla que vamos a segmentar de alguna manera. Va a depender de cada aplicacion. Si hablamos de reconocimiento de habla los segmentos van a ser bien chiquititos, milisegundos, porque este segmentito a que fono corresponde? Asi armamos una oracion.\n",
    "\n",
    "De que segmentos de habla extraemos atributos? Por ejemplo 20 ms.\n",
    "\n",
    "Que atributos sacamos? Pitch track, nivel tonal, intensidad, jitter, schimmer (atributos acusticos de bajo nivel). Ninguno de estos atributos habla del espectro! No hay nada que hable de los fonos en si mismos.\n",
    "\n",
    "* Hay que codificar el espectograma. Los MFCC. Son los atributos mas importantes del habla. Son los que se usan en la posta combinados con los que ya conocemos.\n",
    "\n",
    "Esto es el espectro de un tiempo. Es frecuencia por amplitud. Esto en el tiempo genera el espectograma.\n",
    "\n",
    "* Mapear las frecuencias del espectro a la escala MEL:\n",
    "\n",
    "Recordemos los ejemplos de ver si reproducir un tono puro de 100 hz vs uno de 200hz habia cierta diferencia. Si haciamos lo mismo con 1100 vs 1200 esta diferencia era casi imperceptible!.\n",
    "\n",
    "Eso quiere decir que nuestra percepcion no funciona con una escalal lineal, sino distinta. Esto refleja la escala mel. \n",
    "Esta hecho a mano! Es totalmente empirica. Eso se hace para aprovechar mejor el espectro. Si usamos el otro, pequenias diferencias en 100 a 200 tiene mucha info y en el otro no!. Tenemos que desparramar mejor los bits (mas parecida a lo que nosotros percibimos).  \n",
    "\n",
    "El paso 3 es porque tambien nuestra percepcion de las amplitudes funciona en una escala logaritmica (las mediciones en pascales no respetan nuestra percepcion de la amplitud). El paso 4 le aplico la transformada discreta del coseno como si fuera una senial. Lo trata como si fuera una senial y obtiene un cepstral, es como un spectral pero dado vuelta (es un espectro de un espectro, algo raro).\n",
    "\n",
    "Partimos el espectro en bandas. Cada una de estas banditas va a ser un numerito que me diga cuanta actividad hay ahi. Si tengo esos numeros voy a poder detectar patrones. Si encuentro muchas banditas en gris, detecto silencio. 13 bandas se suelen usar.\n",
    "\n",
    "Si agarramos estos 39 atributos voy a tratar de clasificar que letra representan, cada uno de estos frames tengo que clasificarlo de esa manera, a este en silencio a este en otra cosa a este en otra. Voy a tener g g g g, w w w w, etc. Despues de esto tengo que pasar a la palabra correcta. Hay dos problemas. En lugar de w puede haber clasificado j, podemos tener errores locales! Ahí hay que aprovechar las dependencias! Cada segmento no es independiente del anterior! Primer problema es que no aprovechamos las dependencias que hay dentro del mismo espectro. Del mismo sonido. Segundo problema es que no aprovechamos nada del lenguaje! Entre palabras también hay dependencias! También hay determinada sintaxis que me lleva de una palabra a la otra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconocimiento del habla:\n",
    "Tenemos una señal de audio con habla y el output es la secuencia de palabras. Esto no trata de entender el mensaje!\n",
    "\n",
    "Podemos configurar de forma compacta el espectro de un frame. (generalmente de 20 ms)\n",
    "\n",
    "Este es el primer enfoque naive. Los frames están un poquito superpuestos. De 0-20 el segundo arranca de 10-30. A cada frame le sacamos atributos y a cada uno de estos los clasificamos. \n",
    "\n",
    "Mis MFCCs son mi conjunto de observaciones (de mis frames). Cada o es mi vectorcito de MFCCs. El objetivo es encontrar la secuencia de palabras más probable.\n",
    "\n",
    "La probabilidad de las observaciones dada la secuencia de palabras (la secuencia de palabras ES ESTA), cual es la probabilidad que la secuencia de fonemas sea esta. Por la probabilidad de la tira de palabras.\n",
    "Como maximizo sobre W P(O) lo tacho xq es una constante.\n",
    "\n",
    "Modelo acustico: se resuelve con HMM y GMM. Lo de la derecha es el modelo de lenguaje y lo mdelamos con n-gramas.\n",
    " \n",
    "La probabilidad de las observaciones dada la lista de palabras.\n",
    "Si la hipotesis que dije es hola mundo, cual es la hipotesis que dije hola mundo. Ponderar.\n",
    "La W que maximiza la probabilidad a posteriori. Tenemos una grabacion, cual es la W que tiene la probabilidad mas alta a posteriori. La otra es el prior.\n",
    "\n",
    "Lo vas a modelar de acuerdo a tu contexto. En el contexto de computacion es muy probable que hayas dicho hola mundo.\n",
    "\n",
    "## Modelo acustico:\n",
    "Para modelar el modelo acustico, de una secuencia de observaciones haya sido emitida por una secuencia de palabras W. Porque emitida? Es como que la secuencia de palabras es el objetivo al que queremos llegar y esa secuencia de palabras se materializan en las cosas que despues nosotros observamos. Si esta la palabra HOLA (entidad) se materializa con audio. Queremos modelar la verosimilitud de que una secuencia de observaciones haya sido emitida por una secuencia de palabras.\n",
    "\n",
    "Explico mi modelo con gaussianas!\n",
    "Cada fonema va a tener su propia GMM. Dentro de cada uno de estos GMM vamos a pensar que cada alófono tenga su cluster. Su componente gaussiana. Para todas las S que tenemos en nuestro corpus etiquetado, generamos las gaussianas. En esas 39 dimensiones corro esto. Cuántos son los alófonos? Se prueba a mano. Se prueba con una gaussiana, con cuatro, con ocho, búsqueda binaria. En un momento, cuando baja el modo de evaluar, dejamos la mejor.\n",
    "\n",
    "Supongamos que tenemos para cada fonema un GMM ya entrenado. Lo que me permite este GMM es, la probabilidad de que el fonema j-ésimo emita la observación o. Como funciona esto? Tiro el puntito y me fijo en el eje y que valor toma. Esa es mi probabilidad. La probabilidad de que ese modelo de gaussianas haya emitido esa observación. Si voy al GMM de la O y le tiro una observación. Le tiro la observación a todos los GMM y el que me de la probabilidad más alta, digo que es ese. Si era la de la O, digo que eso es una O. Una GMM por fonema una gaussiana por fono.\n",
    "\n",
    "Maquina de estados finitos. Los estados ocultos son los fonemas que yo voy a querer descubrir. Voy a querer caminar por los estados a medida que voy reconociendo el habla. En la probabilidad aparece el hecho de contexto, sintaxis, tengo probabilidad de transición. La B es la probabilidad de emisión de o en el estado J. Estoy parado en un fonema, por ejemplo S, cual es la probabilidad de emitir una emisión esa observacion. Pi es cual es la probabilidad de empezar en un fonema.\n",
    "\n",
    "Emitir una observacion es producir un vector de MFCC.\n",
    "En habla usamos modelos left-to-right. Porque el tiempo va para adelante.\n",
    "Tenemos estados que vamos a ir avanzando, podemos quedarnos, y cada uno de esos estados puede emitir MFCC.\n",
    "\n",
    "El primer y ultimo nodo no sirven para nada. Hace que sea mas facil la programacion de estas cosas. Estados dummy. Cada uno de esos tiene una GMM colgando, le da la probabilidad de emision de una observacion. Son las gaussianas de 39 dimensiones.\n",
    "\n",
    "Tenemos un GMM por cada TERCIO DE FONEMA. El primer tercio, el comienzo, la parte estable del fonema, y el offset o final del fonema. Esto lo vimos en difonos cuando los partimos a la mitad. Los fonemas tienen 3 momentos, esto lo definieron los fonetistas. Primer estado, captura el comienzo de un fonema. La P y la T captura el silencio y la explosion.\n",
    "\n",
    "El lexico puede ser todo mi diccionario. O un dominio limitado. Para cada palabra del lexico voy a construir un hmm. Un word hmm. Como? Concatentnado los hmm de sus fonemas.\n",
    "\n",
    "Tenemos un HMM que reconoce SOL. Llega un WAV, lo transformo en una secuencia de observaciones (vectores de mfccs). En que consiste usar este hmm para reconocer esto? Tal vez esta gaussiana me va a servir para reconocer solo este cosito, enseguida paso al siguiente (DIBUJITO). Cual es la probabilidad de quedarme en este estado y reconocer esto, y cual es la de pasar aca y reconocer esto. Alguna va a ser mayor! Quedarme y emitir o avanzar y emitir, teniendo en cuenta la probabilidad de avanzar.\n",
    "\n",
    "OJO QUE SON VEROSIMILITUDES.\n",
    "\n",
    "Sacamos los dummies.\n",
    "Una fila por cada tiempo, por cada vectorcito.  Tengo que encontrar el camino óptimo hasta llegar de arriba a abajo a la derecha. Encontrar el camino más probable. Empiezo a la izquierda en tiempo, va avanzando y termino a la derecha. Viterbi es el algoritmo de programación dinámica.\n",
    "\n",
    "Recorrer desde algun estado a algun estado. Se va fijando como llegar de todos los anteriores hasta el primero a la derecha y deja el mejor.\n",
    "\n",
    "La mejor forma de llegar al primer nodo de t-2 es a través de S1.\n",
    "\n",
    "Podemos decir deita o data. Se empiezan a pegotear los HMMs. Esto se hace todo a mano! Siguen siendo de una única palabra!\n",
    "\n",
    "Corro lo que me llega para cada palabra y me quedo con la mejor.\n",
    "\n",
    "Con cada fonema etiquetada en el corpus vamos a entrenar de manera independiente cada gaussiana.\n",
    "Le mando oraciones completas pero con la transcripcion. Esta es la etapa de expectation.\n",
    "La segunda parte es la de maximization.\n",
    "\n",
    "Podemos delimitar un poco las palabras a reconocer definiendo una gramática!\n",
    "\n",
    "Esto eslo que devuelve un reconocedor. El output de un reconocedor es esto. Te da un grafo de izquierda de derecha que te incluye todas las formas más probables de reconocer lo que le pasamos. Las hipótesis más probables. Todas estas pesadas. Puedo usar el dominio en el que estoy para desambiguar.\n",
    "\n",
    "LOS HMM USAN TRIFONOS! NO USAN FONEMAS:\n",
    "\n",
    "Tri fonemas. Si digo ala, la l tiene algo de la a metido. Eso se tiene en cuenta!. La L se modela, está antecedida por una a y seguida por una a. Los trifonos son los que están en azul. Estos son los verdaderos estados ocultos de los HMM.\n",
    "Con esto mejoras las gaussianas, tenes menos ruido. Se elevo al cubo la cantidad de estados!\n",
    "Los conocimientos articulatorios nos permitio bajar la cantidad. Algunos se pueden colapsar en trifonos lógicos.\n",
    "Ente y ende, las caracteristicas de la N pueden ser similares y los colapso en un solo trifono logico.\n",
    "\n",
    "## Modelo del lenguaje:\n",
    "Hay una sintaxis que podemos usar a nuestro favor! En el HMM nos puede dar el ejemplo de arriba!\n",
    "\n",
    "## Predicción de palabras:\n",
    "Uso las n-1 palabras anteriores para predecir la siguiente.\n",
    "SMOOTHING (SUAVIZADO).\n",
    "\n",
    "Pero no es imposible que alguien diga chinese chinese, y esto tiene probabilidad cero! Se fue todo a 0 porque multiplico probabilidades!\n",
    "Qué hacemos? A cada 0 le decimos subi un poquitito. Es una técnica de suavizado.\n",
    "\n",
    "Si buscas un trigrama, y no lo encontras, en vez de dar 0, me voy a los bigramas. Estimo el trigrama con el bigrama."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento:\n",
    "* **Reverberación:**\n",
    "Es el eco mal que se escucha.Se ven como fantasmas, la misma cosa copiandose y atenuandose.\n",
    "\n",
    "Lo puedo meter en el modelo. Grabamos audio de mucha gente bien limpito y después entrenamos un sistema de reconocimiento. El ASR0. Lo que hacemos ahora es ensuciar los datos. Simulando la reverberación. Uno agarra duplica la señal aumenta intensidad etc. Ahi generamos ASR1. Puedo generar lo mismo con ruido de tránsito, y asi un monton. Si fuera a google, le tiro el wav a todos me dan la respuesta y me quedo con el de confiabilidad mas alta.\n",
    "\n",
    "Cuando tengo dos hablantes, y tengo dos microfonos, a un micrófono le va llegar la señal antes la del que esté más cerca. Se puede descomponer las frecuencias que llegan más fuertemente respecto al otro con trigonometría. Aprovechando esa diferencia con cálculos podemos separar las dos fuentes. \n",
    "\n",
    "* **Posprocesamiento:**\n",
    "Es decir, ya reconoci, “avenida rivadavia veinte doce” y quiero “Av. Rivadavia 2012”\n",
    "\n",
    "Pensemos que tenemos un reconocedor perfecto, no le pifia ni a palos.\n",
    "\n",
    "Esos eh, es una disfluencia! Lo primero que hay que hacer es la segmentación de hablantes. En las noticias de radio, reuniones, dialogos telefonicos tenemos muchos hablantes.\n",
    "A la señal de habla la partimos en segmentos. Todavía no decimos quien es el hablante. Podemos hacer clustering. Si un frame se parece al vecino los mergeamos. SI no se parecen, segmento nuevo.\n",
    "\n",
    "Los silencios en los diálogos aparecen mucho mas en un turno que entre turnos. Muchisimo mas.\n",
    "\n",
    "## Diarizacion e identificación.\n",
    "* **Técnicas de clustering:** \n",
    "HMMs con GMMs. La parte de identificación, la cantidad de estados ocultos son la cantidad de personas que pensamos que hay en la conver. Entonces vamos a ir saltando de un hablante a otro y reconociendo los GMMs de cada uno de los dos hablantes. Se pueden hacer las dos tareas juntas. Todo en un solo framework. Osea la diarizacion e identificación.\n",
    "\n",
    "Tenemos que organizar todo lo que se dice. Oraciones, párrafos, temas, etc. No está claro que es una oración. En lo escrito es algo que separa con un punto, pero en el habla no se.\n",
    "\n",
    "El paper lo que dice es lo siguiente, en lugar de pensar directamente como armamos los párrafos, nos tenemos que enfocar en donde esta la atencion puesta, de tal manera que si yo hablo de un mismo tema estoy con la atención en ese tema. Cuando hay un cambio de atencion, entonces ahí es un buen inicio de que tenemos otra unidad. Puede ser párrafo, oración, sección, etc. Lo mismo con las intenciones, las intenciones de lo que estoy diciendo, el cambio de intenciones hay un cambio en la estructura. Se puede modelar con un stack. Empiezo hablando de algo, si detecto que estoy hablando de algo nuevo agrego un nuevo elemento a la pila con todo lo que haya identificado de lo que acabo de decir.\n",
    "\n",
    "Puedo hacer un push y crear uno nuevo, con nuevas intenciones, con nuevos elementos de atención y va a quedar tapando al anterior. Un ejemplito seria, vengo hablando de un tema y digo, para, aproposito y hablo de otra cosa, che y te acordas que la semana que viene toca el pepo? Sisi ya compre la entrada. De que te estaba hablando? Cambio la atención, vuelvo para atras, hago pop. FUNCIONA BASTANTE ASI! ES UN APROX.\n",
    "\n",
    "Si es un orador monotonico, mucho no sirve. Un politico es un placer (no importa si lo que dice es una cagada). Tiene muy bueno manejo de los tiempos, de la voz, etc. Hacemos todo lo mismo cuando hay un punto y aparte? No. Una pregunta retorica es una pregunta? Que carajo es una pregunta? Si te digo una oracion declarativa como el vaso esta sobre la mesa, es una pregunta? Podria serlo! La prosodia me puede jugar en contra a veces o a favor. En la prosodia esta codificada la estructura del discruso en buena medida. Sacarlo es dificil.\n",
    "\n",
    "Dependiendo de las variables acusticas, cuando detecto algun cambio, un modelo de ML puede detectarlo y decir esto es una pregunta, aca va un punto, etc.\n",
    "\n",
    "Si uno no hace énfasis en esto, uno no las nota. Como hacemos para que el bah-uh sean ignorables en nuestro sistema? Una forma de estudiar esto es agarrar un corpus y agarrar gente y marca que aca paso algo (como un uh ah). El tema que después de un tiempo la persona se relaja y le pifia. Es porque estamos acostumbrados a procesarlo automáticamente.\n",
    "\n",
    "Las modelamos como palabras tradicionales!\n",
    "\n",
    "Las disfluencias trato de meterlas en estos patrones. Es un problema de pattern matching (puede ser una expresion regular). Cuando uno se equivoca, cambia la forma de hablar. Sobre todo cuando se corrige, quizá levanta un poco la voz. Cae la calidad de la voz pero muy brevemente. Una computadora lo percibe.\n",
    "\n",
    "El problema es hasta donde tiras a la basura de toda la oracion.\n",
    "\n",
    "FST podemos hacer, consumen palabras y van a escupir símbolos. Fechas ya procesadas por ejemplo.\n",
    "\n",
    "## Test de inteligibilidad: \n",
    "Es exclusivamente si se entienden los fonos o no, si se entienden las palabras o no.\n",
    "Palabras que tienen una estructura sintáctica correcta pero semánticamente es un desastre.\n",
    "\n",
    "## Test de naturalidad del habla sintetizada:\n",
    "La naturalidad es que tan bien suenan las oraciones, los fonos.\n",
    "El test AB es mucho mas facil!, si le digo del 1 al 9 qué valor le pondrias, que se yo! Si le pongo un valor bajo te hechan del laburo? Que onda? Si."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_metadata": {
   "affiliation": "Mozart-Crew, Alexander",
   "author": "Martin 'Cut Pum*' Rey",
   "title": "An introduction to Machine Learning and Speech processing"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
